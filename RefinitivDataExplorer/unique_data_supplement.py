#!/usr/bin/env python3
"""
Unique Data Supplement for LME Daily Report
æ—¢å­˜ã®Daily Reportã«è¼‰ã£ã¦ã„ãªã„é …ç›®ã®ã¿ã‚’å–å¾—ã™ã‚‹ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰äºˆæ¸¬è£œå®Œã‚·ã‚¹ãƒ†ãƒ 

Author: Claude Code  
Created: 2025-06-26
"""

import eikon as ek
import pandas as pd
import json
import time
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import warnings
warnings.filterwarnings('ignore')

class UniqueDataSupplement:
    """Daily Reportã«ç„¡ã„é …ç›®ã®ã¿ã®è£œå®Œãƒ‡ãƒ¼ã‚¿å–å¾—å™¨"""
    
    def __init__(self, config_path: str = "config.json"):
        """åˆæœŸåŒ–"""
        self.config = self._load_config(config_path)
        self.logger = self._setup_logger()
        
        # EIKON APIåˆæœŸåŒ–
        try:
            ek.set_app_key(self.config["eikon_api_key"])
            self.logger.info("EIKON APIåˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            self.logger.error(f"EIKON APIåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _load_config(self, config_path: str) -> Dict:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _setup_logger(self) -> logging.Logger:
        """ãƒ­ã‚°è¨­å®š"""
        logger = logging.getLogger('UniqueDataSupplement')
        logger.setLevel(logging.INFO)
        
        # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›
        handler = logging.StreamHandler()
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        return logger
    
    def get_warrant_status_breakdown(self) -> Dict[str, Any]:
        """LMEåœ¨åº«ã®ãƒ¯ãƒ©ãƒ³ãƒˆçŠ¶æ³è©³ç´°ï¼ˆDaily Reportã«ç„¡ã„é …ç›®ï¼‰"""
        self.logger.info("ãƒ¯ãƒ©ãƒ³ãƒˆçŠ¶æ³è©³ç´°å–å¾—é–‹å§‹...")
        
        warrant_data = {
            "timestamp": datetime.now().isoformat(),
            "warrant_breakdown": {},
            "errors": []
        }
        
        # Daily Reportã«ã¯ç·åœ¨åº«ã®ã¿ã€‚ãƒ¯ãƒ©ãƒ³ãƒˆåˆ†è§£ãƒ‡ãƒ¼ã‚¿ã¯æœªåéŒ²
        warrant_rics = {
            "copper": {
                "live_warrants": "LMCAW=",
                "cancelled_warrants": "LMCACN=", 
                "on_warrant": "LMCAON=",
                "warehouse_stocks": "0#LME-CU-WH"
            },
            "aluminum": {
                "live_warrants": "LMALW=",
                "cancelled_warrants": "LMALCN=",
                "on_warrant": "LMALON=", 
                "warehouse_stocks": "0#LME-AL-WH"
            }
        }
        
        for metal, rics in warrant_rics.items():
            self.logger.info(f"{metal}ãƒ¯ãƒ©ãƒ³ãƒˆè©³ç´°å–å¾—ä¸­...")
            warrant_data["warrant_breakdown"][metal] = {}
            
            for warrant_type, ric in rics.items():
                try:
                    data, err = ek.get_data(ric, ['CF_LAST', 'CF_DATE', 'CF_NAME'])
                    
                    if data is not None and not data.empty:
                        row = data.iloc[0]
                        value = row.get('CF_LAST')
                        
                        if pd.notna(value) and value is not None:
                            warrant_data["warrant_breakdown"][metal][warrant_type] = {
                                "value": float(value),
                                "date": str(row.get('CF_DATE', 'N/A')),
                                "ric": ric,
                                "significance": self._get_warrant_significance(warrant_type)
                            }
                            self.logger.info(f"âœ… {metal} {warrant_type}: {value}")
                        else:
                            self.logger.warning(f"âš ï¸  {metal} {warrant_type} ãƒ‡ãƒ¼ã‚¿ç©º")
                    else:
                        self.logger.warning(f"âš ï¸  {metal} {warrant_type} ã‚¢ã‚¯ã‚»ã‚¹å¤±æ•—: {ric}")
                        if err:
                            warrant_data["errors"].append(f"{ric}: {err}")
                    
                    time.sleep(0.3)
                    
                except Exception as e:
                    error_msg = f"{metal} {warrant_type} ({ric}): {str(e)}"
                    warrant_data["errors"].append(error_msg)
                    self.logger.error(f"âŒ {error_msg}")
            
            time.sleep(0.5)
        
        return warrant_data
    
    def _get_warrant_significance(self, warrant_type: str) -> str:
        """ãƒ¯ãƒ©ãƒ³ãƒˆç¨®åˆ¥ã®æ„ç¾©èª¬æ˜"""
        significance_map = {
            "live_warrants": "Live Warrant = å³åº§ã«å‡ºåº«å¯èƒ½åœ¨åº«ï¼ˆãƒãƒƒã‚¯ãƒ¯ãƒ¼ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³è¦å› ï¼‰",
            "cancelled_warrants": "Cancelled Warrant = å‡ºåº«äºˆç´„æ¸ˆã¿åœ¨åº«ï¼ˆã‚¿ã‚¤ãƒˆæ„Ÿã®å…ˆè¡ŒæŒ‡æ¨™ï¼‰", 
            "on_warrant": "On Warrant = å…¬å¼å€‰åº«åœ¨åº«ç·é‡",
            "warehouse_stocks": "Warehouse Breakdown = å€‰åº«åˆ¥åœ¨åº«åˆ†å¸ƒ"
        }
        return significance_map.get(warrant_type, "åœ¨åº«è©³ç´°æƒ…å ±")
    
    def get_cftc_positioning_data(self) -> Dict[str, Any]:
        """CFTCå»ºç‰æ˜ç´°ï¼ˆDaily Reportã«ç„¡ã„é …ç›®ï¼‰"""
        self.logger.info("CFTCå»ºç‰æ˜ç´°å–å¾—é–‹å§‹...")
        
        cftc_data = {
            "timestamp": datetime.now().isoformat(),
            "positioning": {},
            "errors": []
        }
        
        # Daily Reportã«ã¯å«ã¾ã‚Œã¦ã„ãªã„CFTCãƒã‚¸ã‚·ãƒ§ãƒ³è©³ç´°
        cftc_rics = {
            "copper_futures": {
                "commercial_long": "CFTCCUCOM.L",
                "commercial_short": "CFTCCUCOM.S", 
                "managed_money_long": "CFTCCUMM.L",
                "managed_money_short": "CFTCCUMM.S",
                "reportable_long": "CFTCCUREP.L",
                "reportable_short": "CFTCCUREP.S"
            }
        }
        
        for market, rics in cftc_rics.items():
            self.logger.info(f"{market} CFTCå»ºç‰å–å¾—ä¸­...")
            cftc_data["positioning"][market] = {}
            
            for position_type, ric in rics.items():
                try:
                    data, err = ek.get_data(ric, ['CF_LAST', 'CF_DATE', 'CF_NAME'])
                    
                    if data is not None and not data.empty:
                        row = data.iloc[0]
                        value = row.get('CF_LAST')
                        
                        if pd.notna(value) and value is not None:
                            cftc_data["positioning"][market][position_type] = {
                                "contracts": int(value) if value > 0 else 0,
                                "date": str(row.get('CF_DATE', 'N/A')),
                                "ric": ric
                            }
                            self.logger.info(f"âœ… {market} {position_type}: {value} contracts")
                    
                    time.sleep(0.3)
                    
                except Exception as e:
                    error_msg = f"{market} {position_type} ({ric}): {str(e)}"
                    cftc_data["errors"].append(error_msg)
                    self.logger.debug(f"âš ï¸  {error_msg}")
            
            # ãƒãƒƒãƒˆãƒã‚¸ã‚·ãƒ§ãƒ³è¨ˆç®—
            if market in cftc_data["positioning"]:
                try:
                    mm_long = cftc_data["positioning"][market].get("managed_money_long", {}).get("contracts", 0)
                    mm_short = cftc_data["positioning"][market].get("managed_money_short", {}).get("contracts", 0)
                    
                    if mm_long > 0 and mm_short > 0:
                        net_position = mm_long - mm_short
                        cftc_data["positioning"][market]["managed_money_net"] = {
                            "contracts": net_position,
                            "significance": "æ­£=æŠ•æ©Ÿç­‹è²·ã„è¶Šã—ï¼ˆå¼·æ°—ï¼‰, è² =å£²ã‚Šè¶Šã—ï¼ˆå¼±æ°—ï¼‰"
                        }
                        self.logger.info(f"âœ… {market} MM Net: {net_position} contracts")
                except:
                    pass
        
        return cftc_data
    
    def get_options_market_data(self) -> Dict[str, Any]:
        """ã‚ªãƒ—ã‚·ãƒ§ãƒ³å¸‚å ´ãƒ‡ãƒ¼ã‚¿ï¼ˆDaily Reportã«ç„¡ã„é …ç›®ï¼‰"""
        self.logger.info("ã‚ªãƒ—ã‚·ãƒ§ãƒ³å¸‚å ´ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹...")
        
        options_data = {
            "timestamp": datetime.now().isoformat(),
            "implied_volatility": {},
            "put_call_ratio": {},
            "errors": []
        }
        
        # Daily Reportã«ã¯å«ã¾ã‚Œã¦ã„ãªã„ã‚ªãƒ—ã‚·ãƒ§ãƒ³è©³ç´°
        option_rics = {
            "copper": {
                "atm_iv": "CMCUATM=IV",
                "iv_skew": "CMCUSKEW=", 
                "put_call_ratio": "CMCUPCR=",
                "delta_hedge": "CMCUDELTA="
            },
            "aluminum": {
                "atm_iv": "CMALATM=IV",
                "iv_skew": "CMALSKEW=",
                "put_call_ratio": "CMALPCR=", 
                "delta_hedge": "CMALDELTA="
            }
        }
        
        for metal, rics in option_rics.items():
            self.logger.info(f"{metal}ã‚ªãƒ—ã‚·ãƒ§ãƒ³è©³ç´°å–å¾—ä¸­...")
            options_data["implied_volatility"][metal] = {}
            
            for option_type, ric in rics.items():
                try:
                    data, err = ek.get_data(ric, ['CF_LAST', 'CF_DATE', 'CF_NAME'])
                    
                    if data is not None and not data.empty:
                        row = data.iloc[0]
                        value = row.get('CF_LAST')
                        
                        if pd.notna(value) and value is not None:
                            options_data["implied_volatility"][metal][option_type] = {
                                "value": float(value),
                                "date": str(row.get('CF_DATE', 'N/A')),
                                "ric": ric,
                                "interpretation": self._get_option_interpretation(option_type, value)
                            }
                            self.logger.info(f"âœ… {metal} {option_type}: {value}")
                    
                    time.sleep(0.3)
                    
                except Exception as e:
                    error_msg = f"{metal} {option_type} ({ric}): {str(e)}"
                    options_data["errors"].append(error_msg)
                    self.logger.debug(f"âš ï¸  {error_msg}")
        
        return options_data
    
    def _get_option_interpretation(self, option_type: str, value: float) -> str:
        """ã‚ªãƒ—ã‚·ãƒ§ãƒ³æŒ‡æ¨™ã®è§£é‡ˆ"""
        if option_type == "atm_iv":
            if value > 30:
                return f"é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£({value:.1f}%) - å¸‚å ´ä¸å®‰å®š"
            elif value < 15:
                return f"ä½ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£({value:.1f}%) - å¸‚å ´å®‰å®š"
            else:
                return f"ä¸­ç¨‹åº¦ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£({value:.1f}%)"
        elif option_type == "put_call_ratio":
            if value > 1.2:
                return f"ãƒ—ãƒƒãƒˆå„ªå‹¢({value:.2f}) - å¼±æ°—ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ"
            elif value < 0.8:
                return f"ã‚³ãƒ¼ãƒ«å„ªå‹¢({value:.2f}) - å¼·æ°—ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ"
            else:
                return f"ä¸­ç«‹({value:.2f})"
        return f"å€¤: {value}"
    
    def get_baltic_shipping_details(self) -> Dict[str, Any]:
        """ãƒãƒ«ãƒãƒƒã‚¯æŒ‡æ•°è©³ç´°ï¼ˆDaily Reportã®ç°¡å˜ãªèª¬æ˜ã‚’è©³ç´°åŒ–ï¼‰"""
        self.logger.info("ãƒãƒ«ãƒãƒƒã‚¯æŒ‡æ•°è©³ç´°å–å¾—é–‹å§‹...")
        
        baltic_data = {
            "timestamp": datetime.now().isoformat(),
            "shipping_rates": {},
            "route_breakdown": {},
            "errors": []
        }
        
        # Daily Reportã«ã¯ãƒãƒ«ãƒãƒƒã‚¯æŒ‡æ•°ã®æ¦‚è¦ã®ã¿ã€‚è©³ç´°ã¯æœªåéŒ²
        baltic_rics = {
            "overall": ".BADI",
            "capesize": ".BACI", 
            "panamax": ".BAPI",
            "supramax": ".BASI",
            "handysize": ".BHSI"
        }
        
        route_rics = {
            "pacific_iron_ore": ".BATCI4",  # Pacific iron ore routes
            "atlantic_iron_ore": ".BATCI5", # Atlantic iron ore routes  
            "pacific_coal": ".BATCI6",      # Pacific coal routes
            "grains": ".BATCI7"             # Grains routes
        }
        
        # èˆ¹èˆ¶ã‚µã‚¤ã‚ºåˆ¥ãƒ¬ãƒ¼ãƒˆ
        for ship_type, ric in baltic_rics.items():
            try:
                data, err = ek.get_data(ric, ['CF_LAST', 'CF_DATE', 'CF_NAME', 'PCTCHNG'])
                
                if data is not None and not data.empty:
                    row = data.iloc[0]
                    value = row.get('CF_LAST')
                    change = row.get('PCTCHNG')
                    
                    if pd.notna(value):
                        baltic_data["shipping_rates"][ship_type] = {
                            "index_value": float(value),
                            "daily_change_pct": float(change) if pd.notna(change) else None,
                            "date": str(row.get('CF_DATE', 'N/A')),
                            "name": str(row.get('CF_NAME', ship_type)),
                            "significance": self._get_ship_significance(ship_type)
                        }
                        self.logger.info(f"âœ… {ship_type}: {value}")
                
                time.sleep(0.3)
                
            except Exception as e:
                error_msg = f"{ship_type} ({ric}): {str(e)}"
                baltic_data["errors"].append(error_msg)
                self.logger.debug(f"âš ï¸  {error_msg}")
        
        # èˆªè·¯åˆ¥è©³ç´°
        for route_type, ric in route_rics.items():
            try:
                data, err = ek.get_data(ric, ['CF_LAST', 'CF_DATE', 'CF_NAME'])
                
                if data is not None and not data.empty:
                    row = data.iloc[0]
                    value = row.get('CF_LAST')
                    
                    if pd.notna(value):
                        baltic_data["route_breakdown"][route_type] = {
                            "rate": float(value),
                            "date": str(row.get('CF_DATE', 'N/A')),
                            "route_description": self._get_route_description(route_type)
                        }
                        self.logger.info(f"âœ… {route_type}: {value}")
                
                time.sleep(0.3)
                
            except Exception as e:
                baltic_data["errors"].append(f"{route_type}: {str(e)}")
        
        return baltic_data
    
    def _get_ship_significance(self, ship_type: str) -> str:
        """èˆ¹èˆ¶ã‚¿ã‚¤ãƒ—ã®æ„ç¾©èª¬æ˜"""
        significance_map = {
            "overall": "ç·åˆæŒ‡æ•° - å…¨èˆ¹èˆ¶ã‚¿ã‚¤ãƒ—ã®åŠ é‡å¹³å‡",
            "capesize": "å¤§å‹èˆ¹(180k+ DWT) - é‰„é‰±çŸ³ãƒ»çŸ³ç‚­è¼¸é€ä¸»ä½“", 
            "panamax": "ä¸­å‹èˆ¹(65-90k DWT) - ç©€ç‰©ãƒ»çŸ³ç‚­è¼¸é€",
            "supramax": "ä¸­å°å‹èˆ¹(50-65k DWT) - å¤šæ§˜è²¨ç‰©å¯¾å¿œ",
            "handysize": "å°å‹èˆ¹(15-35k DWT) - è¿‘è·é›¢ãƒ»å°å£è¼¸é€"
        }
        return significance_map.get(ship_type, "æµ·é‹ãƒ¬ãƒ¼ãƒˆæŒ‡æ¨™")
    
    def _get_route_description(self, route_type: str) -> str:
        """èˆªè·¯ã®èª¬æ˜"""
        route_map = {
            "pacific_iron_ore": "å¤ªå¹³æ´‹é‰„é‰±çŸ³èˆªè·¯ - è±ªå·â†’ä¸­å›½ãƒ»æ—¥æœ¬",
            "atlantic_iron_ore": "å¤§è¥¿æ´‹é‰„é‰±çŸ³èˆªè·¯ - ãƒ–ãƒ©ã‚¸ãƒ«â†’æ¬§å·ãƒ»ä¸­å›½", 
            "pacific_coal": "å¤ªå¹³æ´‹çŸ³ç‚­èˆªè·¯ - è±ªå·ãƒ»ã‚¤ãƒ³ãƒ‰ãƒã‚·ã‚¢â†’ã‚¢ã‚¸ã‚¢",
            "grains": "ç©€ç‰©èˆªè·¯ - ç±³å›½ãƒ»å—ç±³â†’ã‚¢ã‚¸ã‚¢ãƒ»æ¬§å·"
        }
        return route_map.get(route_type, "æµ·é‹èˆªè·¯")
    
    def get_forward_curve_analysis(self) -> Dict[str, Any]:
        """ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ã‚«ãƒ¼ãƒ–è©³ç´°åˆ†æï¼ˆDaily Reportã‚ˆã‚Šè©³ç´°ï¼‰"""
        self.logger.info("ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ã‚«ãƒ¼ãƒ–è©³ç´°åˆ†æé–‹å§‹...")
        
        curve_data = {
            "timestamp": datetime.now().isoformat(),
            "curve_shape": {},
            "contango_backwardation": {},
            "errors": []
        }
        
        # Daily Reportã«ã¯ä¸€éƒ¨æœŸé–“ã®ã‚«ãƒ¼ãƒ–ã®ã¿ã€‚å…¨æœŸé–“æ§‹é€ ã¯æœªåéŒ²
        metals = ["copper", "aluminum", "zinc", "lead", "nickel", "tin"]
        
        for metal in metals:
            self.logger.info(f"{metal}ã‚«ãƒ¼ãƒ–æ§‹é€ åˆ†æä¸­...")
            
            # 3ãƒ¶æœˆã€œ24ãƒ¶æœˆã®ä¸»è¦é™æœˆ
            ric_pattern = f"CM{metal.upper()[:2]}U" if metal != "aluminum" else "CMAL"
            
            periods = {
                "3m": "3",
                "6m": "M", 
                "12m": "3",  # ç¿Œå¹´3æœˆ
                "15m": "M",  # ç¿Œå¹´6æœˆ
                "24m": "3"   # 2å¹´å¾Œ3æœˆ
            }
            
            curve_prices = {}
            
            for period, month_code in periods.items():
                try:
                    year_suffix = "25" if period in ["3m", "6m"] else "26"
                    if period in ["24m"]:
                        year_suffix = "27"
                    
                    ric = f"{ric_pattern}{month_code}{year_suffix}"
                    
                    data, err = ek.get_data(ric, ['CF_LAST', 'CF_DATE'])
                    
                    if data is not None and not data.empty:
                        row = data.iloc[0]
                        price = row.get('CF_LAST')
                        
                        if pd.notna(price):
                            curve_prices[period] = {
                                "price": float(price),
                                "ric": ric,
                                "date": str(row.get('CF_DATE', 'N/A'))
                            }
                            self.logger.info(f"âœ… {metal} {period}: ${price}")
                    
                    time.sleep(0.2)
                    
                except Exception as e:
                    curve_data["errors"].append(f"{metal} {period}: {str(e)}")
            
            # ã‚«ãƒ¼ãƒ–å½¢çŠ¶åˆ†æ
            if len(curve_prices) >= 3:
                curve_data["curve_shape"][metal] = self._analyze_curve_shape(curve_prices)
                curve_data["contango_backwardation"][metal] = self._analyze_contango_backwardation(curve_prices)
        
        return curve_data
    
    def _analyze_curve_shape(self, prices: Dict) -> Dict:
        """ã‚«ãƒ¼ãƒ–å½¢çŠ¶åˆ†æ"""
        if "3m" not in prices or "24m" not in prices:
            return {"shape": "insufficient_data"}
        
        front_price = prices["3m"]["price"]
        back_price = prices["24m"]["price"]
        
        total_slope = (back_price - front_price) / front_price * 100
        
        shape_analysis = {
            "front_to_back_slope_pct": round(total_slope, 2),
            "shape_description": "",
            "market_implication": ""
        }
        
        if total_slope > 5:
            shape_analysis["shape_description"] = "Steep Contango"
            shape_analysis["market_implication"] = "ä¾›çµ¦éå‰°ãƒ»é‡‘åˆ©ã‚³ã‚¹ãƒˆé«˜ãƒ»éœ€è¦å¼±å«ã¿"
        elif total_slope > 1:
            shape_analysis["shape_description"] = "Moderate Contango" 
            shape_analysis["market_implication"] = "ç·©ã‚„ã‹ãªä¾›çµ¦éå‰°ãƒ»æ­£å¸¸ãªCarry Cost"
        elif total_slope < -5:
            shape_analysis["shape_description"] = "Steep Backwardation"
            shape_analysis["market_implication"] = "ç¾ç‰©ã‚¿ã‚¤ãƒˆãƒ»ç·Šæ€¥éœ€è¦ãƒ»ä¾›çµ¦ä¸å®‰"
        elif total_slope < -1:
            shape_analysis["shape_description"] = "Moderate Backwardation"
            shape_analysis["market_implication"] = "ç¾ç‰©ã‚„ã‚„ä¸è¶³ãƒ»éœ€è¦å …èª¿"
        else:
            shape_analysis["shape_description"] = "Flat/Neutral"
            shape_analysis["market_implication"] = "éœ€çµ¦å‡è¡¡ãƒ»ä¸­ç«‹çš„å¸‚å ´"
        
        return shape_analysis
    
    def _analyze_contango_backwardation(self, prices: Dict) -> Dict:
        """ã‚³ãƒ³ã‚¿ãƒ³ã‚´ãƒ»ãƒãƒƒã‚¯ãƒ¯ãƒ¼ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³åˆ†æ"""
        analysis = {
            "near_far_spreads": {},
            "carry_cost_analysis": {}
        }
        
        # è¿‘é™-é é™ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰
        if "3m" in prices and "6m" in prices:
            front = prices["3m"]["price"]
            next_front = prices["6m"]["price"]
            spread_3_6 = next_front - front
            
            analysis["near_far_spreads"]["3m_6m_spread"] = {
                "spread_value": round(spread_3_6, 2),
                "spread_pct": round(spread_3_6 / front * 100, 2),
                "annualized_rate": round((spread_3_6 / front) * 4 * 100, 2)  # 3ãƒ¶æœˆâ†’å¹´ç‡
            }
        
        return analysis
    
    def generate_unique_supplement_report(self) -> str:
        """Daily Reportè£œå®Œç”¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        self.logger.info("Daily Reportè£œå®Œãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé–‹å§‹...")
        
        # å„ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿å–å¾—
        warrant_data = self.get_warrant_status_breakdown()
        cftc_data = self.get_cftc_positioning_data()
        options_data = self.get_options_market_data()
        baltic_data = self.get_baltic_shipping_details()
        curve_data = self.get_forward_curve_analysis()
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report_lines = []
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼
        report_lines.append("=" * 80)
        report_lines.append("ã€Webç‰ˆClaudeç”¨ã€‘Daily Reportè£œå®Œãƒ‡ãƒ¼ã‚¿ - ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰äºˆæ¸¬ç‰¹åŒ–")
        report_lines.append("=" * 80)
        report_lines.append(f"ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}")
        report_lines.append("ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: Refinitiv EIKON APIï¼ˆDaily ReportæœªåéŒ²é …ç›®ã®ã¿ï¼‰")
        report_lines.append("")
        report_lines.append("ã€é‡è¦ã€‘ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯æ—¢å­˜ã®Daily Reportã¨ä½µç”¨ã™ã‚‹ã“ã¨ã§ã€")
        report_lines.append("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰äºˆæ¸¬ç²¾åº¦ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹å°‚é–€çš„è£œå®Œãƒ‡ãƒ¼ã‚¿ã§ã™ã€‚")
        report_lines.append("")
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        report_lines.append("ã€Claudeåˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€‘")
        report_lines.append("æ—¢å­˜ã®LME Daily Reportã¨ä»¥ä¸‹ã®è£œå®Œãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã—ã¦ã€")
        report_lines.append("LMEé‡‘å±å…ˆç‰©ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ï¼ˆã‚³ãƒ³ã‚¿ãƒ³ã‚´/ãƒãƒƒã‚¯ãƒ¯ãƒ¼ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰ã®")
        report_lines.append("é«˜ç²¾åº¦äºˆæ¸¬åˆ†æã‚’å®Ÿæ–½ã—ã¦ãã ã•ã„ã€‚")
        report_lines.append("")
        
        # 1. ãƒ¯ãƒ©ãƒ³ãƒˆè©³ç´°åˆ†è§£
        report_lines.append("=" * 60)
        report_lines.append("ã€è£œå®Œãƒ‡ãƒ¼ã‚¿1ã€‘LMEåœ¨åº«ãƒ¯ãƒ©ãƒ³ãƒˆè©³ç´°åˆ†è§£")
        report_lines.append("=" * 60)
        report_lines.append("â€»Daily Reportã«ã¯ç·åœ¨åº«ã®ã¿ã€‚ä»¥ä¸‹ã¯å†…éƒ¨æ§‹é€ åˆ†è§£")
        report_lines.append("")
        
        if "warrant_breakdown" in warrant_data:
            for metal, breakdown in warrant_data["warrant_breakdown"].items():
                if breakdown:
                    report_lines.append(f"--- {metal.upper()}ãƒ¯ãƒ©ãƒ³ãƒˆæ§‹é€  ---")
                    for warrant_type, data in breakdown.items():
                        value = data.get("value", "N/A")
                        date = data.get("date", "N/A")
                        significance = data.get("significance", "")
                        report_lines.append(f"  {warrant_type}: {value} ãƒˆãƒ³ (æ›´æ–°: {date})")
                        if significance:
                            report_lines.append(f"    â†’ {significance}")
                    report_lines.append("")
        
        # 2. CFTCå»ºç‰æ˜ç´°
        report_lines.append("=" * 60)
        report_lines.append("ã€è£œå®Œãƒ‡ãƒ¼ã‚¿2ã€‘CFTCå»ºç‰æ˜ç´°ï¼ˆæŠ•æ©Ÿç­‹ãƒã‚¸ã‚·ãƒ§ãƒ³ï¼‰")
        report_lines.append("=" * 60)
        report_lines.append("â€»Daily Reportã«ã¯å«ã¾ã‚Œãªã„è©³ç´°ãƒã‚¸ã‚·ãƒ§ãƒ³åˆ†æ")
        report_lines.append("")
        
        if "positioning" in cftc_data:
            for market, positions in cftc_data["positioning"].items():
                if positions:
                    report_lines.append(f"--- {market.upper()}å»ºç‰çŠ¶æ³ ---")
                    for position_type, data in positions.items():
                        if "contracts" in data:
                            contracts = data.get("contracts", 0)
                            date = data.get("date", "N/A")
                            report_lines.append(f"  {position_type}: {contracts:,} contracts (æ›´æ–°: {date})")
                        elif "significance" in data:
                            significance = data.get("significance", "")
                            contracts = data.get("contracts", 0)
                            report_lines.append(f"  {position_type}: {contracts:,} contracts")
                            report_lines.append(f"    â†’ {significance}")
                    report_lines.append("")
        
        # 3. ã‚ªãƒ—ã‚·ãƒ§ãƒ³å¸‚å ´ãƒ‡ãƒ¼ã‚¿
        report_lines.append("=" * 60)
        report_lines.append("ã€è£œå®Œãƒ‡ãƒ¼ã‚¿3ã€‘ã‚ªãƒ—ã‚·ãƒ§ãƒ³å¸‚å ´åˆ†æ")
        report_lines.append("=" * 60)
        report_lines.append("â€»Daily Reportã«ã¯å«ã¾ã‚Œãªã„ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ»ãƒªã‚¹ã‚¯åˆ†æ")
        report_lines.append("")
        
        if "implied_volatility" in options_data:
            for metal, iv_data in options_data["implied_volatility"].items():
                if iv_data:
                    report_lines.append(f"--- {metal.upper()}ã‚ªãƒ—ã‚·ãƒ§ãƒ³å¸‚å ´ ---")
                    for option_type, data in iv_data.items():
                        value = data.get("value", "N/A")
                        interpretation = data.get("interpretation", "")
                        date = data.get("date", "N/A")
                        report_lines.append(f"  {option_type}: {value} (æ›´æ–°: {date})")
                        if interpretation:
                            report_lines.append(f"    â†’ {interpretation}")
                    report_lines.append("")
        
        # 4. ãƒãƒ«ãƒãƒƒã‚¯æŒ‡æ•°è©³ç´°
        report_lines.append("=" * 60)
        report_lines.append("ã€è£œå®Œãƒ‡ãƒ¼ã‚¿4ã€‘ãƒãƒ«ãƒãƒƒã‚¯æŒ‡æ•°è©³ç´°åˆ†è§£")
        report_lines.append("=" * 60)
        report_lines.append("â€»Daily Reportã«ã¯ç·åˆæŒ‡æ•°ã®ã¿ã€‚ä»¥ä¸‹ã¯èˆ¹èˆ¶åˆ¥ãƒ»èˆªè·¯åˆ¥è©³ç´°")
        report_lines.append("")
        
        if "shipping_rates" in baltic_data:
            report_lines.append("--- èˆ¹èˆ¶ã‚¿ã‚¤ãƒ—åˆ¥ãƒ¬ãƒ¼ãƒˆ ---")
            for ship_type, data in baltic_data["shipping_rates"].items():
                value = data.get("index_value", "N/A")
                change = data.get("daily_change_pct", "N/A")
                significance = data.get("significance", "")
                report_lines.append(f"  {ship_type}: {value}")
                if change != "N/A":
                    report_lines.append(f"    æ—¥æ¬¡å¤‰å‹•: {change:+.2f}%")
                if significance:
                    report_lines.append(f"    â†’ {significance}")
            report_lines.append("")
        
        if "route_breakdown" in baltic_data:
            report_lines.append("--- ä¸»è¦èˆªè·¯ãƒ¬ãƒ¼ãƒˆ ---")
            for route, data in baltic_data["route_breakdown"].items():
                rate = data.get("rate", "N/A")
                description = data.get("route_description", "")
                report_lines.append(f"  {route}: {rate}")
                if description:
                    report_lines.append(f"    â†’ {description}")
            report_lines.append("")
        
        # 5. ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ã‚«ãƒ¼ãƒ–è©³ç´°
        report_lines.append("=" * 60)
        report_lines.append("ã€è£œå®Œãƒ‡ãƒ¼ã‚¿5ã€‘ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ã‚«ãƒ¼ãƒ–è©³ç´°åˆ†æ")
        report_lines.append("=" * 60)
        report_lines.append("â€»Daily Reportã‚ˆã‚Šè©³ç´°ãªæœŸé–“æ§‹é€ ãƒ»ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰åˆ†æ")
        report_lines.append("")
        
        if "curve_shape" in curve_data:
            for metal, shape_analysis in curve_data["curve_shape"].items():
                if shape_analysis and "shape_description" in shape_analysis:
                    report_lines.append(f"--- {metal.upper()}ã‚«ãƒ¼ãƒ–å½¢çŠ¶ ---")
                    slope = shape_analysis.get("front_to_back_slope_pct", "N/A")
                    shape = shape_analysis.get("shape_description", "N/A")
                    implication = shape_analysis.get("market_implication", "")
                    
                    report_lines.append(f"  ãƒ•ãƒ­ãƒ³ãƒˆ-ãƒãƒƒã‚¯å‹¾é…: {slope}%")
                    report_lines.append(f"  ã‚«ãƒ¼ãƒ–å½¢çŠ¶: {shape}")
                    if implication:
                        report_lines.append(f"  å¸‚å ´å«æ„: {implication}")
                    report_lines.append("")
        
        # ã‚¨ãƒ©ãƒ¼ã‚µãƒãƒªãƒ¼
        all_errors = []
        all_errors.extend(warrant_data.get("errors", []))
        all_errors.extend(cftc_data.get("errors", []))
        all_errors.extend(options_data.get("errors", []))
        all_errors.extend(baltic_data.get("errors", []))
        all_errors.extend(curve_data.get("errors", []))
        
        if all_errors:
            report_lines.append("--- ãƒ‡ãƒ¼ã‚¿å–å¾—åˆ¶é™äº‹é … ---")
            for error in all_errors[:8]:
                report_lines.append(f"  â€¢ {error}")
            report_lines.append("")
        
        # çµ±åˆåˆ†ææŒ‡ç¤º
        report_lines.append("=" * 80)
        report_lines.append("ã€çµ±åˆåˆ†ææŒ‡ç¤ºã€‘Daily Report + è£œå®Œãƒ‡ãƒ¼ã‚¿")
        report_lines.append("=" * 80)
        report_lines.append("")
        report_lines.append("ä»¥ä¸‹ã®æ‰‹é †ã§çµ±åˆã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰åˆ†æã‚’å®Ÿæ–½ã—ã¦ãã ã•ã„ï¼š")
        report_lines.append("")
        report_lines.append("1. ãƒ¯ãƒ©ãƒ³ãƒˆæ§‹é€  Ã— ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿:")
        report_lines.append("   - ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒ¯ãƒ©ãƒ³ãƒˆæ¯”ç‡ã¨ãƒãƒƒã‚¯ãƒ¯ãƒ¼ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ç›¸é–¢")
        report_lines.append("   - Live Warrantæ¸›å°‘ã«ã‚ˆã‚‹ç¾ç‰©ã‚¿ã‚¤ãƒˆåŒ–äºˆæ¸¬")
        report_lines.append("")
        report_lines.append("2. CFTCå»ºç‰ Ã— åœ¨åº«ãƒ‡ãƒ¼ã‚¿:")
        report_lines.append("   - æŠ•æ©Ÿç­‹Net Positionæ–¹å‘ã¨åœ¨åº«ãƒˆãƒ¬ãƒ³ãƒ‰æ•´åˆæ€§")
        report_lines.append("   - Commercial vs Managed Money ã®åŠ›é–¢ä¿‚")
        report_lines.append("")
        report_lines.append("3. ã‚ªãƒ—ã‚·ãƒ§ãƒ³IV Ã— ä¾¡æ ¼ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£:")
        report_lines.append("   - IVä¸Šæ˜‡ã¨ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰å¤‰å‹•æ‹¡å¤§ã®é–¢ä¿‚")
        report_lines.append("   - Put/Callæ¯”ç‡ã«ã‚ˆã‚‹æ–¹å‘æ€§ãƒã‚¤ã‚¢ã‚¹")
        report_lines.append("")
        report_lines.append("4. ãƒãƒ«ãƒãƒƒã‚¯è©³ç´° Ã— ç‰©æµã‚³ã‚¹ãƒˆ:")
        report_lines.append("   - èˆ¹èˆ¶ã‚¿ã‚¤ãƒ—åˆ¥ãƒ¬ãƒ¼ãƒˆä¸Šæ˜‡ã®Carry Costå½±éŸ¿")
        report_lines.append("   - èˆªè·¯åˆ¥æ··é›‘ã«ã‚ˆã‚‹åœ°åŸŸãƒ—ãƒ¬ãƒŸã‚¢ãƒ å¤‰å‹•")
        report_lines.append("")
        report_lines.append("5. ã‚«ãƒ¼ãƒ–å½¢çŠ¶ Ã— ãƒã‚¯ãƒ­ç’°å¢ƒ:")
        report_lines.append("   - é‡‘åˆ©å¤‰å‹•ã¨Contango/Backwardationæ§‹é€ ")
        report_lines.append("   - æœŸé–“æ§‹é€ å¤‰åŒ–ã®å…·ä½“çš„æ™‚æœŸã¨ãƒˆãƒªã‚¬ãƒ¼äºˆæ¸¬")
        report_lines.append("")
        report_lines.append("ã€æœ€çµ‚å‡ºåŠ›è¦æ±‚ã€‘")
        report_lines.append("- é‡‘å±åˆ¥ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰æ–¹å‘äºˆæ¸¬ï¼ˆ1-2é€±é–“ã€1-3ãƒ¶æœˆï¼‰")
        report_lines.append("- å…·ä½“çš„ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒ»ã‚¨ã‚°ã‚¸ãƒƒãƒˆæˆ¦ç•¥")
        report_lines.append("- ãƒªã‚¹ã‚¯ã‚·ãƒŠãƒªã‚ªã¨ç®¡ç†æ–¹æ³•")
        report_lines.append("=" * 80)
        
        return "\n".join(report_lines)
    
    def save_report(self, report_content: str, filename: str = None) -> str:
        """ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜"""
        if filename is None:
            filename = f"Daily_Report_Supplement_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(report_content)
            self.logger.info(f"è£œå®Œãƒ¬ãƒãƒ¼ãƒˆä¿å­˜å®Œäº†: {filename}")
            return filename
        except Exception as e:
            self.logger.error(f"ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            raise

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    try:
        supplement = UniqueDataSupplement()
        
        print("ğŸ“Š Daily Reportè£œå®Œãƒ‡ãƒ¼ã‚¿ã‚·ã‚¹ãƒ†ãƒ ")
        print("=" * 50)
        print("æ—¢å­˜ãƒ¬ãƒãƒ¼ãƒˆã«ç„¡ã„é …ç›®ã®ã¿ã‚’å–å¾—:")
        print("â€¢ LMEåœ¨åº«ãƒ¯ãƒ©ãƒ³ãƒˆè©³ç´°åˆ†è§£")
        print("â€¢ CFTCå»ºç‰æ˜ç´°ï¼ˆæŠ•æ©Ÿç­‹ãƒã‚¸ã‚·ãƒ§ãƒ³ï¼‰")
        print("â€¢ ã‚ªãƒ—ã‚·ãƒ§ãƒ³å¸‚å ´ãƒ‡ãƒ¼ã‚¿ï¼ˆIVãƒ»P/Cæ¯”ç‡ï¼‰")
        print("â€¢ ãƒãƒ«ãƒãƒƒã‚¯æŒ‡æ•°è©³ç´°åˆ†è§£")
        print("â€¢ ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ã‚«ãƒ¼ãƒ–è©³ç´°åˆ†æ")
        print("=" * 50)
        
        # è£œå®Œãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report_content = supplement.generate_unique_supplement_report()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        saved_filename = supplement.save_report(report_content)
        
        print(f"\nâœ… Daily Reportè£œå®Œãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†!")
        print(f"ğŸ“„ ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«: {saved_filename}")
        print(f"ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {len(report_content.encode('utf-8')):,} bytes")
        print("\nğŸ”— æ—¢å­˜ã®Daily Reportã¨ä½µç”¨ã—ã¦Webç‰ˆClaudeã§åˆ†æã—ã¦ãã ã•ã„ã€‚")
        print("ğŸ’¡ è£œå®Œå†…å®¹: Daily Reportã«ç„¡ã„ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰äºˆæ¸¬ç‰¹åŒ–ãƒ‡ãƒ¼ã‚¿")
        
        return 0
        
    except Exception as e:
        print(f"âŒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        return 1

if __name__ == "__main__":
    exit(main())