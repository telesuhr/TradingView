#!/usr/bin/env python3
"""
Refinitiv Data Web Claude Reporter
Webç‰ˆClaudeç”¨ã®ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 

Author: Claude Code  
Created: 2025-06-26
"""

import eikon as ek
import pandas as pd
import json
import time
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import warnings
warnings.filterwarnings('ignore')

class RefinitivWebClaudeReporter:
    """Webç‰ˆClaudeç”¨ãƒ‡ãƒ¼ã‚¿ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå™¨"""
    
    def __init__(self, config_path: str = "config.json"):
        """åˆæœŸåŒ–"""
        self.config = self._load_config(config_path)
        self.logger = self._setup_logger()
        
        # EIKON APIåˆæœŸåŒ–
        try:
            ek.set_app_key(self.config["eikon_api_key"])
            self.logger.info("EIKON APIåˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            self.logger.error(f"EIKON APIåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _load_config(self, config_path: str) -> Dict:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _setup_logger(self) -> logging.Logger:
        """ãƒ­ã‚°è¨­å®š"""
        logger = logging.getLogger('WebClaudeReporter')
        logger.setLevel(logging.INFO)
        
        # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›
        handler = logging.StreamHandler()
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        return logger
    
    def get_inventory_data(self) -> Dict[str, Any]:
        """åœ¨åº«ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        self.logger.info("åœ¨åº«ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹...")
        
        inventory_data = {
            "timestamp": datetime.now().isoformat(),
            "lme_stocks": {},
            "other_exchanges": {},
            "smm_news": []
        }
        
        try:
            # LMEåœ¨åº«ãƒ‡ãƒ¼ã‚¿
            lme_data, lme_err = ek.get_data("0#LME-STOCKS", ['CF_NAME', 'CF_LAST', 'CF_DATE'])
            if lme_data is not None and not lme_data.empty:
                for _, row in lme_data.iterrows():
                    name = row.get('CF_NAME', 'Unknown')
                    value = row.get('CF_LAST', 'N/A')
                    date = row.get('CF_DATE', 'N/A')
                    inventory_data["lme_stocks"][name] = {
                        "value": value,
                        "date": str(date),
                        "unit": "tonnes"
                    }
            
            # SHFEåœ¨åº«ãƒ‡ãƒ¼ã‚¿
            shfe_data, shfe_err = ek.get_data("0#SGH-STOCKS", ['CF_NAME', 'CF_LAST', 'CF_DATE'])
            if shfe_data is not None and not shfe_data.empty:
                inventory_data["other_exchanges"]["SHFE"] = []
                for _, row in shfe_data.iterrows():
                    inventory_data["other_exchanges"]["SHFE"].append({
                        "name": row.get('CF_NAME', 'Unknown'),
                        "value": row.get('CF_LAST', 'N/A'),
                        "date": str(row.get('CF_DATE', 'N/A'))
                    })
            
            # COMEXåœ¨åº«ãƒ‡ãƒ¼ã‚¿
            comex_data, comex_err = ek.get_data("0#HG-STOCK", ['CF_NAME', 'CF_LAST', 'CF_DATE'])
            if comex_data is not None and not comex_data.empty:
                inventory_data["other_exchanges"]["COMEX"] = []
                for _, row in comex_data.iterrows():
                    inventory_data["other_exchanges"]["COMEX"].append({
                        "name": row.get('CF_NAME', 'Unknown'),
                        "value": row.get('CF_LAST', 'N/A'),
                        "date": str(row.get('CF_DATE', 'N/A'))
                    })
            
            # SMMé–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹
            try:
                smm_headlines = ek.get_news_headlines(query="SMM shadow inventory", count=5)
                if smm_headlines is not None and len(smm_headlines) > 0:
                    for _, row in smm_headlines.iterrows():
                        inventory_data["smm_news"].append({
                            "headline": row.get('text', 'N/A'),
                            "date": str(row.get('versionCreated', 'N/A')),
                            "source": row.get('sourceCode', 'N/A')
                        })
            except Exception as news_err:
                self.logger.warning(f"SMM ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: {news_err}")
            
            time.sleep(1)  # APIåˆ¶é™å¯¾ç­–
            
        except Exception as e:
            self.logger.error(f"åœ¨åº«ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            inventory_data["error"] = str(e)
        
        return inventory_data
    
    def get_shipping_logistics_data(self) -> Dict[str, Any]:
        """ç‰©æµãƒ»è¼¸é€ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        self.logger.info("ç‰©æµãƒ»è¼¸é€ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹...")
        
        logistics_data = {
            "timestamp": datetime.now().isoformat(),
            "baltic_index": {},
            "port_news": [],
            "lme_queue_data": {}
        }
        
        try:
            # ãƒãƒ«ãƒãƒƒã‚¯æŒ‡æ•°
            baltic_data, baltic_err = ek.get_data(".BADI", ['CF_LAST', 'CF_DATE', 'CF_NAME'])
            if baltic_data is not None and not baltic_data.empty:
                row = baltic_data.iloc[0]
                logistics_data["baltic_index"] = {
                    "value": row.get('CF_LAST', 'N/A'),
                    "date": str(row.get('CF_DATE', 'N/A')),
                    "name": row.get('CF_NAME', 'Baltic Dry Index')
                }
                
                # æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚‚å–å¾—
                end_date = datetime.now()
                start_date = end_date - timedelta(days=30)
                baltic_ts = ek.get_timeseries(
                    ".BADI",
                    start_date=start_date.strftime('%Y-%m-%d'),
                    end_date=end_date.strftime('%Y-%m-%d'),
                    fields=['CLOSE']
                )
                if baltic_ts is not None and not baltic_ts.empty:
                    logistics_data["baltic_index"]["30day_trend"] = {
                        "start_value": float(baltic_ts['CLOSE'].iloc[0]),
                        "end_value": float(baltic_ts['CLOSE'].iloc[-1]),
                        "change_pct": ((float(baltic_ts['CLOSE'].iloc[-1]) - float(baltic_ts['CLOSE'].iloc[0])) / float(baltic_ts['CLOSE'].iloc[0])) * 100,
                        "data_points": len(baltic_ts)
                    }
            
            # ä¸»è¦æ¸¯æ¹¾ãƒ‹ãƒ¥ãƒ¼ã‚¹
            port_keywords = ["Shanghai port", "Rotterdam port", "shipping delay", "port congestion"]
            for keyword in port_keywords[:2]:  # æœ€åˆã®2ã¤ã‚’ãƒ†ã‚¹ãƒˆ
                try:
                    port_headlines = ek.get_news_headlines(query=keyword, count=3)
                    if port_headlines is not None and len(port_headlines) > 0:
                        for _, row in port_headlines.iterrows():
                            logistics_data["port_news"].append({
                                "keyword": keyword,
                                "headline": row.get('text', 'N/A'),
                                "date": str(row.get('versionCreated', 'N/A')),
                                "source": row.get('sourceCode', 'N/A')
                            })
                    time.sleep(0.5)  # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é–“ã®çŸ­ã„é–“éš”
                except Exception as port_err:
                    self.logger.debug(f"æ¸¯æ¹¾ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼ ({keyword}): {port_err}")
            
            # LMEå€‰åº«å¾…ã¡è¡Œåˆ—
            try:
                lme_queue_data, queue_err = ek.get_data("LMEQ", ['CF_NAME', 'CF_LAST'])
                if lme_queue_data is not None and not lme_queue_data.empty:
                    logistics_data["lme_queue_data"] = {
                        "queue_info": lme_queue_data.to_dict('records'),
                        "data_points": len(lme_queue_data)
                    }
            except Exception as queue_err:
                self.logger.debug(f"LMEå¾…ã¡è¡Œåˆ—ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {queue_err}")
            
            time.sleep(1)
            
        except Exception as e:
            self.logger.error(f"ç‰©æµãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            logistics_data["error"] = str(e)
        
        return logistics_data
    
    def get_premiums_and_sentiment(self) -> Dict[str, Any]:
        """ç¾ç‰©ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ã¨ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿å–å¾—"""
        self.logger.info("ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ãƒ»ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹...")
        
        sentiment_data = {
            "timestamp": datetime.now().isoformat(),
            "physical_premiums": {},
            "cftc_positions": {},
            "options_data": {},
            "analyst_sentiment": []
        }
        
        try:
            # ç¾ç‰©ãƒ—ãƒ¬ãƒŸã‚¢ãƒ 
            premium_rics = ["AL-PREM-JP", "CU-PREM-SH"]
            for ric in premium_rics:
                try:
                    prem_data, prem_err = ek.get_data(ric, ['CF_LAST', 'CF_DATE', 'CF_NAME'])
                    if prem_data is not None and not prem_data.empty:
                        row = prem_data.iloc[0]
                        sentiment_data["physical_premiums"][ric] = {
                            "value": row.get('CF_LAST', 'N/A'),
                            "date": str(row.get('CF_DATE', 'N/A')),
                            "name": row.get('CF_NAME', ric)
                        }
                except Exception as prem_err:
                    self.logger.debug(f"ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼ ({ric}): {prem_err}")
            
            # CFTCå»ºç‰ãƒ‡ãƒ¼ã‚¿
            cftc_rics = ["0#CFTC-COPPER:", "0#CFTC-ALUM:"]
            for ric in cftc_rics:
                try:
                    cftc_data, cftc_err = ek.get_data(ric, ['CF_NAME', 'CF_LAST', 'CF_DATE'])
                    if cftc_data is not None and not cftc_data.empty:
                        sentiment_data["cftc_positions"][ric] = {
                            "positions": cftc_data.to_dict('records'),
                            "data_points": len(cftc_data)
                        }
                except Exception as cftc_err:
                    self.logger.debug(f"CFTCãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼ ({ric}): {cftc_err}")
            
            # ã‚ªãƒ—ã‚·ãƒ§ãƒ³IVãƒ‡ãƒ¼ã‚¿
            option_rics = ["CMCU=IVOL", "CMAL=IVOL"]
            for ric in option_rics:
                try:
                    iv_data, iv_err = ek.get_data(ric, ['CF_LAST', 'CF_DATE', 'CF_NAME'])
                    if iv_data is not None and not iv_data.empty:
                        row = iv_data.iloc[0]
                        sentiment_data["options_data"][ric] = {
                            "implied_volatility": row.get('CF_LAST', 'N/A'),
                            "date": str(row.get('CF_DATE', 'N/A')),
                            "name": row.get('CF_NAME', ric)
                        }
                except Exception as iv_err:
                    self.logger.debug(f"ã‚ªãƒ—ã‚·ãƒ§ãƒ³IVãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼ ({ric}): {iv_err}")
            
            # ã‚¢ãƒŠãƒªã‚¹ãƒˆãƒ»ãƒ¬ãƒãƒ¼ãƒˆé–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹
            analyst_keywords = ["Macquarie copper", "Goldman Sachs metals", "JPMorgan commodity"]
            for keyword in analyst_keywords:
                try:
                    analyst_headlines = ek.get_news_headlines(query=keyword, count=2)
                    if analyst_headlines is not None and len(analyst_headlines) > 0:
                        for _, row in analyst_headlines.iterrows():
                            sentiment_data["analyst_sentiment"].append({
                                "keyword": keyword,
                                "headline": row.get('text', 'N/A'),
                                "date": str(row.get('versionCreated', 'N/A')),
                                "source": row.get('sourceCode', 'N/A')
                            })
                    time.sleep(0.5)
                except Exception as analyst_err:
                    self.logger.debug(f"ã‚¢ãƒŠãƒªã‚¹ãƒˆãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼ ({keyword}): {analyst_err}")
            
            time.sleep(1)
            
        except Exception as e:
            self.logger.error(f"ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            sentiment_data["error"] = str(e)
        
        return sentiment_data
    
    def get_macro_economic_data(self) -> Dict[str, Any]:
        """ãƒã‚¯ãƒ­çµŒæ¸ˆãƒ‡ãƒ¼ã‚¿å–å¾—"""
        self.logger.info("ãƒã‚¯ãƒ­çµŒæ¸ˆãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹...")
        
        macro_data = {
            "timestamp": datetime.now().isoformat(),
            "pmi_indicators": {},
            "auto_sales": {},
            "fixed_investment": {},
            "interest_rates": {}
        }
        
        try:
            # PMIæŒ‡æ¨™
            pmi_rics = {
                "china_pmi": "CN.PMIMFG.IDX",
                "us_pmi": "US.PMIMFG.IDX", 
                "eu_pmi": "EU.PMIMFG.IDX"
            }
            
            for name, ric in pmi_rics.items():
                try:
                    pmi_data, pmi_err = ek.get_data(ric, ['CF_LAST', 'CF_DATE', 'CF_NAME'])
                    if pmi_data is not None and not pmi_data.empty:
                        row = pmi_data.iloc[0]
                        macro_data["pmi_indicators"][name] = {
                            "value": row.get('CF_LAST', 'N/A'),
                            "date": str(row.get('CF_DATE', 'N/A')),
                            "name": row.get('CF_NAME', name)
                        }
                except Exception as pmi_err:
                    self.logger.debug(f"PMIãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼ ({name}): {pmi_err}")
            
            # è‡ªå‹•è»Šè²©å£²
            auto_rics = {
                "china_auto": "CN.AUTOSALES",
                "us_auto": "US.AUTOSALES"
            }
            
            for name, ric in auto_rics.items():
                try:
                    auto_data, auto_err = ek.get_data(ric, ['CF_LAST', 'CF_DATE', 'CF_NAME'])
                    if auto_data is not None and not auto_data.empty:
                        row = auto_data.iloc[0]
                        macro_data["auto_sales"][name] = {
                            "value": row.get('CF_LAST', 'N/A'),
                            "date": str(row.get('CF_DATE', 'N/A')),
                            "name": row.get('CF_NAME', name)
                        }
                except Exception as auto_err:
                    self.logger.debug(f"è‡ªå‹•è»Šè²©å£²ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼ ({name}): {auto_err}")
            
            # ä¸­å›½å›ºå®šè³‡ç”£æŠ•è³‡
            try:
                fixed_data, fixed_err = ek.get_data("CN.FIXEDINV.YOY", ['CF_LAST', 'CF_DATE', 'CF_NAME'])
                if fixed_data is not None and not fixed_data.empty:
                    row = fixed_data.iloc[0]
                    macro_data["fixed_investment"] = {
                        "value": row.get('CF_LAST', 'N/A'),
                        "date": str(row.get('CF_DATE', 'N/A')),
                        "name": row.get('CF_NAME', 'China Fixed Investment YoY')
                    }
            except Exception as fixed_err:
                self.logger.debug(f"å›ºå®šæŠ•è³‡ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {fixed_err}")
            
            # ä¸»è¦æ”¿ç­–é‡‘åˆ©
            rate_rics = {
                "fed_funds": "USDFF=",
                "ecb_rate": "EUREPO=",
                "pboc_rate": "CNREPO="
            }
            
            for name, ric in rate_rics.items():
                try:
                    rate_data, rate_err = ek.get_data(ric, ['CF_LAST', 'CF_DATE', 'CF_NAME'])
                    if rate_data is not None and not rate_data.empty:
                        row = rate_data.iloc[0]
                        macro_data["interest_rates"][name] = {
                            "value": row.get('CF_LAST', 'N/A'),
                            "date": str(row.get('CF_DATE', 'N/A')),
                            "name": row.get('CF_NAME', name)
                        }
                except Exception as rate_err:
                    self.logger.debug(f"é‡‘åˆ©ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼ ({name}): {rate_err}")
            
            time.sleep(1)
            
        except Exception as e:
            self.logger.error(f"ãƒã‚¯ãƒ­çµŒæ¸ˆãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            macro_data["error"] = str(e)
        
        return macro_data
    
    def generate_web_claude_report(self) -> str:
        """Webç‰ˆClaudeç”¨ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        self.logger.info("Webç‰ˆClaudeç”¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé–‹å§‹...")
        
        # å„ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®ãƒ‡ãƒ¼ã‚¿å–å¾—
        inventory_data = self.get_inventory_data()
        logistics_data = self.get_shipping_logistics_data()
        sentiment_data = self.get_premiums_and_sentiment()
        macro_data = self.get_macro_economic_data()
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report_lines = []
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼
        report_lines.append("=" * 80)
        report_lines.append("ã€Webç‰ˆClaudeç”¨ã€‘ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰äºˆæ¸¬ç²¾åº¦å‘ä¸Šãƒ‡ãƒ¼ã‚¿ãƒ¬ãƒãƒ¼ãƒˆ")
        report_lines.append("=" * 80)
        report_lines.append(f"ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}")
        report_lines.append(f"ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: Refinitiv EIKON API")
        report_lines.append("")
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆéƒ¨åˆ†
        report_lines.append("ã€Claudeåˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€‘")
        report_lines.append("ä»¥ä¸‹ã®Refinitivã‹ã‚‰å–å¾—ã—ãŸãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é‡‘å±å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚’åŸºã«ã€")
        report_lines.append("LMEé‡‘å±å…ˆç‰©ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ï¼ˆã‚³ãƒ³ã‚¿ãƒ³ã‚´/ãƒãƒƒã‚¯ãƒ¯ãƒ¼ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰ã®äºˆæ¸¬åˆ†æã‚’è¡Œã£ã¦ãã ã•ã„ã€‚")
        report_lines.append("")
        report_lines.append("ã€åˆ†æè¦ä»¶ã€‘")
        report_lines.append("- å„ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆãŒç¤ºã™ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰æ–¹å‘ã¸ã®å½±éŸ¿ã‚’è©•ä¾¡")
        report_lines.append("- åœ¨åº«çŠ¶æ³ã€ç‰©æµã‚³ã‚¹ãƒˆã€ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã€ãƒã‚¯ãƒ­è¦å› ã®ç·åˆåˆ†æ")
        report_lines.append("- çŸ­æœŸï¼ˆ1-2é€±é–“ï¼‰ã€ä¸­æœŸï¼ˆ1-3ãƒ¶æœˆï¼‰ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰äºˆæ¸¬")
        report_lines.append("- ãƒªã‚¹ã‚¯è¦å› ã¨ã‚·ãƒŠãƒªã‚ªåˆ†æ")
        report_lines.append("- å…·ä½“çš„ãªãƒˆãƒ¬ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ç¤ºå”†")
        report_lines.append("")
        
        # ã‚«ãƒ†ã‚´ãƒªãƒ¼1: åœ¨åº«ãƒ»éœ€çµ¦ãƒ‡ãƒ¼ã‚¿
        report_lines.append("=" * 60)
        report_lines.append("ã€ã‚«ãƒ†ã‚´ãƒªãƒ¼1ã€‘ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åœ¨åº«ãƒ»éœ€çµ¦ãƒ‡ãƒ¼ã‚¿")
        report_lines.append("=" * 60)
        
        report_lines.append("\n--- LMEå…¬å¼åœ¨åº« ---")
        if "lme_stocks" in inventory_data:
            for metal, data in inventory_data["lme_stocks"].items():
                if isinstance(data, dict) and "value" in data:
                    report_lines.append(f"  {metal}: {data['value']} {data.get('unit', '')} (æ›´æ–°: {data.get('date', 'N/A')})")
        
        report_lines.append("\n--- ä»–å–å¼•æ‰€åœ¨åº« ---")
        if "other_exchanges" in inventory_data:
            for exchange, stocks in inventory_data["other_exchanges"].items():
                report_lines.append(f"  ã€{exchange}ã€‘")
                if isinstance(stocks, list):
                    for stock in stocks[:3]:  # æœ€åˆã®3ã¤ã‚’è¡¨ç¤º
                        report_lines.append(f"    {stock.get('name', 'N/A')}: {stock.get('value', 'N/A')} (æ—¥ä»˜: {stock.get('date', 'N/A')})")
        
        report_lines.append("\n--- SMMéå…¬è¡¨åœ¨åº«æƒ…å ± ---")
        if "smm_news" in inventory_data and inventory_data["smm_news"]:
            for i, news in enumerate(inventory_data["smm_news"][:3]):
                report_lines.append(f"  [{i+1}] {news.get('headline', 'N/A')}")
                report_lines.append(f"      æ—¥æ™‚: {news.get('date', 'N/A')} | ã‚½ãƒ¼ã‚¹: {news.get('source', 'N/A')}")
        
        # ã‚«ãƒ†ã‚´ãƒªãƒ¼2: ç‰©æµãƒ»è¼¸é€ãƒ‡ãƒ¼ã‚¿
        report_lines.append("\n" + "=" * 60)
        report_lines.append("ã€ã‚«ãƒ†ã‚´ãƒªãƒ¼2ã€‘ç‰©æµãƒ»è¼¸é€ã‚³ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿")
        report_lines.append("=" * 60)
        
        report_lines.append("\n--- ãƒãƒ«ãƒãƒƒã‚¯æµ·é‹æŒ‡æ•° ---")
        if "baltic_index" in logistics_data:
            baltic = logistics_data["baltic_index"]
            report_lines.append(f"  ç¾åœ¨å€¤: {baltic.get('value', 'N/A')} (æ›´æ–°: {baltic.get('date', 'N/A')})")
            if "30day_trend" in baltic:
                trend = baltic["30day_trend"]
                report_lines.append(f"  30æ—¥ãƒˆãƒ¬ãƒ³ãƒ‰: {trend.get('start_value', 'N/A')} â†’ {trend.get('end_value', 'N/A')}")
                report_lines.append(f"  å¤‰å‹•ç‡: {trend.get('change_pct', 'N/A'):.2f}% ({trend.get('data_points', 0)}ãƒã‚¤ãƒ³ãƒˆ)")
        
        report_lines.append("\n--- ä¸»è¦æ¸¯æ¹¾ãƒ»ç‰©æµãƒ‹ãƒ¥ãƒ¼ã‚¹ ---")
        if "port_news" in logistics_data and logistics_data["port_news"]:
            for i, news in enumerate(logistics_data["port_news"][:4]):
                report_lines.append(f"  [{i+1}] ({news.get('keyword', 'N/A')}) {news.get('headline', 'N/A')}")
                report_lines.append(f"      æ—¥æ™‚: {news.get('date', 'N/A')}")
        
        # ã‚«ãƒ†ã‚´ãƒªãƒ¼3: ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆãƒ»ãƒã‚¸ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿
        report_lines.append("\n" + "=" * 60)
        report_lines.append("ã€ã‚«ãƒ†ã‚´ãƒªãƒ¼3ã€‘å¸‚å ´ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆãƒ»ãƒã‚¸ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿")
        report_lines.append("=" * 60)
        
        report_lines.append("\n--- ç¾ç‰©ãƒ—ãƒ¬ãƒŸã‚¢ãƒ  ---")
        if "physical_premiums" in sentiment_data:
            for ric, data in sentiment_data["physical_premiums"].items():
                if isinstance(data, dict):
                    report_lines.append(f"  {data.get('name', ric)}: {data.get('value', 'N/A')} (æ›´æ–°: {data.get('date', 'N/A')})")
        
        report_lines.append("\n--- CFTCå»ºç‰æ˜ç´° ---")
        if "cftc_positions" in sentiment_data:
            for ric, data in sentiment_data["cftc_positions"].items():
                if isinstance(data, dict) and "positions" in data:
                    report_lines.append(f"  ã€{ric}ã€‘")
                    for pos in data["positions"][:3]:
                        report_lines.append(f"    {pos.get('CF_NAME', 'N/A')}: {pos.get('CF_LAST', 'N/A')} (æ—¥ä»˜: {pos.get('CF_DATE', 'N/A')})")
        
        report_lines.append("\n--- ã‚ªãƒ—ã‚·ãƒ§ãƒ³å¸‚å ´ãƒ‡ãƒ¼ã‚¿ ---")
        if "options_data" in sentiment_data:
            for ric, data in sentiment_data["options_data"].items():
                if isinstance(data, dict):
                    report_lines.append(f"  {data.get('name', ric)} IV: {data.get('implied_volatility', 'N/A')}% (æ›´æ–°: {data.get('date', 'N/A')})")
        
        report_lines.append("\n--- ã‚¢ãƒŠãƒªã‚¹ãƒˆãƒ»ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ ---")
        if "analyst_sentiment" in sentiment_data and sentiment_data["analyst_sentiment"]:
            for i, news in enumerate(sentiment_data["analyst_sentiment"][:4]):
                report_lines.append(f"  [{i+1}] ({news.get('keyword', 'N/A')}) {news.get('headline', 'N/A')}")
                report_lines.append(f"      æ—¥æ™‚: {news.get('date', 'N/A')}")
        
        # ã‚«ãƒ†ã‚´ãƒªãƒ¼4: ãƒã‚¯ãƒ­çµŒæ¸ˆãƒ‡ãƒ¼ã‚¿
        report_lines.append("\n" + "=" * 60)
        report_lines.append("ã€ã‚«ãƒ†ã‚´ãƒªãƒ¼4ã€‘ãƒã‚¯ãƒ­çµŒæ¸ˆãƒ»é‡‘åˆ©ãƒ‡ãƒ¼ã‚¿")
        report_lines.append("=" * 60)
        
        report_lines.append("\n--- è£½é€ æ¥­PMIæŒ‡æ¨™ ---")
        if "pmi_indicators" in macro_data:
            for name, data in macro_data["pmi_indicators"].items():
                if isinstance(data, dict):
                    report_lines.append(f"  {data.get('name', name)}: {data.get('value', 'N/A')} (æ›´æ–°: {data.get('date', 'N/A')})")
        
        report_lines.append("\n--- è‡ªå‹•è»Šè²©å£²çµ±è¨ˆ ---")
        if "auto_sales" in macro_data:
            for name, data in macro_data["auto_sales"].items():
                if isinstance(data, dict):
                    report_lines.append(f"  {data.get('name', name)}: {data.get('value', 'N/A')} (æ›´æ–°: {data.get('date', 'N/A')})")
        
        report_lines.append("\n--- ä¸­å›½å›ºå®šè³‡ç”£æŠ•è³‡ ---")
        if "fixed_investment" in macro_data and isinstance(macro_data["fixed_investment"], dict):
            fixed = macro_data["fixed_investment"]
            report_lines.append(f"  {fixed.get('name', 'Fixed Investment')}: {fixed.get('value', 'N/A')}% YoY (æ›´æ–°: {fixed.get('date', 'N/A')})")
        
        report_lines.append("\n--- ä¸»è¦å›½æ”¿ç­–é‡‘åˆ© ---")
        if "interest_rates" in macro_data:
            for name, data in macro_data["interest_rates"].items():
                if isinstance(data, dict):
                    report_lines.append(f"  {data.get('name', name)}: {data.get('value', 'N/A')}% (æ›´æ–°: {data.get('date', 'N/A')})")
        
        # ãƒ•ãƒƒã‚¿ãƒ¼
        report_lines.append("\n" + "=" * 80)
        report_lines.append("ã€åˆ†ææŒ‡ç¤ºã€‘")
        report_lines.append("ä¸Šè¨˜ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã—ã¦ä»¥ä¸‹ã®è¦³ç‚¹ã‹ã‚‰åˆ†æã—ã¦ãã ã•ã„ï¼š")
        report_lines.append("")
        report_lines.append("1. åœ¨åº«çŠ¶æ³åˆ†æ:")
        report_lines.append("   - LMEå…¬å¼åœ¨åº« vs éå…¬è¡¨åœ¨åº«ã®ä¹–é›¢")
        report_lines.append("   - åœ°åŸŸåˆ¥åœ¨åº«åˆ†å¸ƒã¨ã‚¤ãƒ³ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³")
        report_lines.append("")
        report_lines.append("2. ç‰©æµã‚³ã‚¹ãƒˆå½±éŸ¿:")
        report_lines.append("   - ãƒãƒ«ãƒãƒƒã‚¯æŒ‡æ•°ãƒˆãƒ¬ãƒ³ãƒ‰ãŒCarry Costã«ä¸ãˆã‚‹å½±éŸ¿")
        report_lines.append("   - æ¸¯æ¹¾çŠ¶æ³ã«ã‚ˆã‚‹ç¾ç‰©ã‚¿ã‚¤ãƒˆæ„Ÿ")
        report_lines.append("")
        report_lines.append("3. å¸‚å ´ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ:")
        report_lines.append("   - ç¾ç‰©ãƒ—ãƒ¬ãƒŸã‚¢ãƒ å¤‰å‹•ã®å…ˆè¡ŒæŒ‡æ¨™æ€§")
        report_lines.append("   - CFTCæŠ•æ©Ÿç­‹ãƒã‚¸ã‚·ãƒ§ãƒ³ã®åã‚Š")
        report_lines.append("   - ã‚ªãƒ—ã‚·ãƒ§ãƒ³IVãŒç¤ºã™ãƒªã‚¹ã‚¯èªè­˜")
        report_lines.append("")
        report_lines.append("4. ãƒã‚¯ãƒ­ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚º:")
        report_lines.append("   - PMIã€è‡ªå‹•è»Šè²©å£²ç­‰ã®éœ€è¦å…ˆè¡ŒæŒ‡æ¨™")
        report_lines.append("   - é‡‘åˆ©ç’°å¢ƒãŒCost of Carryã«ä¸ãˆã‚‹å½±éŸ¿")
        report_lines.append("")
        report_lines.append("5. ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰äºˆæ¸¬:")
        report_lines.append("   - ã‚³ãƒ³ã‚¿ãƒ³ã‚´/ãƒãƒƒã‚¯ãƒ¯ãƒ¼ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³æ–¹å‘")
        report_lines.append("   - æœŸé–“æ§‹é€ ã®å¤‰åŒ–äºˆæ¸¬")
        report_lines.append("   - ãƒˆãƒ¬ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æˆ¦ç•¥ã®ææ¡ˆ")
        report_lines.append("")
        report_lines.append("=" * 80)
        
        return "\n".join(report_lines)
    
    def save_report(self, report_content: str, filename: str = None) -> str:
        """ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        if filename is None:
            filename = f"Refinitiv_Spread_Analysis_Data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(report_content)
            self.logger.info(f"ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜å®Œäº†: {filename}")
            return filename
        except Exception as e:
            self.logger.error(f"ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            raise

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    try:
        reporter = RefinitivWebClaudeReporter()
        
        print("ğŸŒ Webç‰ˆClaudeç”¨ Refinitivãƒ‡ãƒ¼ã‚¿ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ")
        print("=" * 60)
        print("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰äºˆæ¸¬ç²¾åº¦å‘ä¸Šã®ãŸã‚ã®åŒ…æ‹¬çš„ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
        print("=" * 60)
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report_content = reporter.generate_web_claude_report()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        saved_filename = reporter.save_report(report_content)
        
        print(f"\nâœ… ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†!")
        print(f"ğŸ“„ ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«: {saved_filename}")
        print(f"ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {len(report_content.encode('utf-8')):,} bytes")
        print("\nğŸ”— ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Webç‰ˆClaudeã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦åˆ†æã‚’ä¾é ¼ã—ã¦ãã ã•ã„ã€‚")
        
        return 0
        
    except Exception as e:
        print(f"âŒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        return 1

if __name__ == "__main__":
    exit(main())