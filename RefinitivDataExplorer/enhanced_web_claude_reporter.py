#!/usr/bin/env python3
"""
Enhanced Refinitiv Data Web Claude Reporter
Webç‰ˆClaudeç”¨ã®æ”¹è‰¯ç‰ˆã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 

Author: Claude Code  
Created: 2025-06-26
"""

import eikon as ek
import pandas as pd
import json
import time
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import warnings
warnings.filterwarnings('ignore')

class EnhancedRefinitivWebClaudeReporter:
    """æ”¹è‰¯ç‰ˆWebç‰ˆClaudeç”¨ãƒ‡ãƒ¼ã‚¿ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå™¨"""
    
    def __init__(self, config_path: str = "config.json"):
        """åˆæœŸåŒ–"""
        self.config = self._load_config(config_path)
        self.logger = self._setup_logger()
        
        # EIKON APIåˆæœŸåŒ–
        try:
            ek.set_app_key(self.config["eikon_api_key"])
            self.logger.info("EIKON APIåˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            self.logger.error(f"EIKON APIåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _load_config(self, config_path: str) -> Dict:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _setup_logger(self) -> logging.Logger:
        """ãƒ­ã‚°è¨­å®š"""
        logger = logging.getLogger('EnhancedWebClaudeReporter')
        logger.setLevel(logging.INFO)
        
        # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›
        handler = logging.StreamHandler()
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        return logger
    
    def get_enhanced_lme_inventory(self) -> Dict[str, Any]:
        """æ”¹è‰¯ç‰ˆLMEåœ¨åº«ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆã‚ªãƒ³ãƒ¯ãƒ©ãƒ³ãƒˆãƒ»ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒ¯ãƒ©ãƒ³ãƒˆåˆ†è§£ï¼‰"""
        self.logger.info("æ”¹è‰¯ç‰ˆLMEåœ¨åº«ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹...")
        
        inventory_data = {
            "timestamp": datetime.now().isoformat(),
            "lme_detailed_stocks": {},
            "lme_warrant_status": {},
            "other_exchanges": {},
            "errors": []
        }
        
        try:
            # LMEåœ¨åº«ã®è©³ç´°RICå®šç¾©
            lme_detailed_rics = {
                "copper": {
                    "total": "CMCU-STX-LME",
                    "on_warrant": "CMCU-SOW-LME", 
                    "cancelled": "CMCU-SCW-LME",
                    "live_warrant": "CMCU-SLW-LME"
                },
                "aluminum": {
                    "total": "CMAL-STX-LME",
                    "on_warrant": "CMAL-SOW-LME",
                    "cancelled": "CMAL-SCW-LME", 
                    "live_warrant": "CMAL-SLW-LME"
                },
                "zinc": {
                    "total": "CMZN-STX-LME",
                    "on_warrant": "CMZN-SOW-LME",
                    "cancelled": "CMZN-SCW-LME",
                    "live_warrant": "CMZN-SLW-LME"
                },
                "lead": {
                    "total": "CMPB-STX-LME", 
                    "on_warrant": "CMPB-SOW-LME",
                    "cancelled": "CMPB-SCW-LME",
                    "live_warrant": "CMPB-SLW-LME"
                },
                "nickel": {
                    "total": "CMNI-STX-LME",
                    "on_warrant": "CMNI-SOW-LME", 
                    "cancelled": "CMNI-SCW-LME",
                    "live_warrant": "CMNI-SLW-LME"
                },
                "tin": {
                    "total": "CMSN-STX-LME",
                    "on_warrant": "CMSN-SOW-LME",
                    "cancelled": "CMSN-SCW-LME", 
                    "live_warrant": "CMSN-SLW-LME"
                }
            }
            
            # å„é‡‘å±ã®è©³ç´°åœ¨åº«ãƒ‡ãƒ¼ã‚¿å–å¾—
            for metal, rics in lme_detailed_rics.items():
                self.logger.info(f"{metal}åœ¨åº«ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
                inventory_data["lme_detailed_stocks"][metal] = {}
                
                for stock_type, ric in rics.items():
                    try:
                        # get_dataã‚’ä½¿ã£ã¦è©³ç´°ãƒ‡ãƒ¼ã‚¿å–å¾—
                        data, err = ek.get_data(ric, ['CF_LAST', 'CF_DATE', 'CF_NAME'])
                        
                        if data is not None and not data.empty and len(data) > 0:
                            row = data.iloc[0]
                            value = row.get('CF_LAST')
                            date = row.get('CF_DATE')
                            name = row.get('CF_NAME', ric)
                            
                            # NaNã‚„Noneã®ãƒã‚§ãƒƒã‚¯
                            if pd.notna(value) and value is not None:
                                inventory_data["lme_detailed_stocks"][metal][stock_type] = {
                                    "value": float(value),
                                    "date": str(date) if pd.notna(date) else "N/A",
                                    "ric": ric,
                                    "name": str(name) if pd.notna(name) else ric
                                }
                                self.logger.info(f"âœ… {metal} {stock_type}: {value}")
                            else:
                                self.logger.warning(f"âš ï¸  {metal} {stock_type} ãƒ‡ãƒ¼ã‚¿ãŒç©º: {ric}")
                        else:
                            self.logger.warning(f"âš ï¸  {metal} {stock_type} ã‚¢ã‚¯ã‚»ã‚¹å¤±æ•—: {ric}")
                            if err:
                                inventory_data["errors"].append(f"{ric}: {err}")
                        
                        time.sleep(0.3)  # APIåˆ¶é™å¯¾ç­–
                        
                    except Exception as e:
                        error_msg = f"{metal} {stock_type} ({ric}): {str(e)}"
                        inventory_data["errors"].append(error_msg)
                        self.logger.error(f"âŒ {error_msg}")
                
                time.sleep(0.5)  # é‡‘å±é–“ã®é–“éš”
            
            # ä»£æ›¿LMEåœ¨åº«ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆ0#ãƒã‚§ãƒ¼ãƒ³ã‹ã‚‰å€‹åˆ¥ã«ï¼‰
            self.logger.info("ä»£æ›¿LMEåœ¨åº«ãƒã‚§ãƒ¼ãƒ³å–å¾—...")
            try:
                lme_chain_data, chain_err = ek.get_data("0#LME-STOCKS", ['CF_LAST', 'CF_DATE', 'CF_NAME'])
                if lme_chain_data is not None and not lme_chain_data.empty:
                    inventory_data["lme_warrant_status"]["chain_data"] = []
                    for _, row in lme_chain_data.iterrows():
                        name = row.get('CF_NAME')
                        value = row.get('CF_LAST') 
                        date = row.get('CF_DATE')
                        
                        if pd.notna(value) and pd.notna(name):
                            inventory_data["lme_warrant_status"]["chain_data"].append({
                                "name": str(name),
                                "value": float(value),
                                "date": str(date) if pd.notna(date) else "N/A"
                            })
                    
                    self.logger.info(f"âœ… LMEãƒã‚§ãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿: {len(inventory_data['lme_warrant_status']['chain_data'])}é …ç›®")
            except Exception as e:
                inventory_data["errors"].append(f"LME chain data: {str(e)}")
            
            # SHFEåœ¨åº«ãƒ‡ãƒ¼ã‚¿ï¼ˆå€‹åˆ¥RICï¼‰
            shfe_rics = {
                "copper": "CU-STX-SGH",
                "aluminum": "AL-STX-SGH", 
                "zinc": "ZN-STX-SGH",
                "lead": "PB-STX-SGH",
                "nickel": "NI-STX-SGH",
                "tin": "SN-STX-SGH"
            }
            
            inventory_data["other_exchanges"]["SHFE"] = {}
            for metal, ric in shfe_rics.items():
                try:
                    data, err = ek.get_data(ric, ['CF_LAST', 'CF_DATE', 'CF_NAME'])
                    if data is not None and not data.empty:
                        row = data.iloc[0]
                        value = row.get('CF_LAST')
                        if pd.notna(value):
                            inventory_data["other_exchanges"]["SHFE"][metal] = {
                                "value": float(value),
                                "date": str(row.get('CF_DATE', 'N/A')),
                                "ric": ric
                            }
                            self.logger.info(f"âœ… SHFE {metal}: {value}")
                    time.sleep(0.2)
                except Exception as e:
                    inventory_data["errors"].append(f"SHFE {metal} ({ric}): {str(e)}")
            
            time.sleep(1)
            
        except Exception as e:
            self.logger.error(f"åœ¨åº«ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            inventory_data["errors"].append(f"General inventory error: {str(e)}")
        
        return inventory_data
    
    def get_enhanced_news_data(self) -> Dict[str, Any]:
        """æ”¹è‰¯ç‰ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆæœ¬æ–‡ä»˜ãï¼‰"""
        self.logger.info("æ”¹è‰¯ç‰ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹...")
        
        news_data = {
            "timestamp": datetime.now().isoformat(),
            "market_moving_news": [],
            "analyst_reports": [],
            "supply_disruption_news": [],
            "errors": []
        }
        
        try:
            # å¸‚å ´ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãƒ‹ãƒ¥ãƒ¼ã‚¹
            market_keywords = [
                "LME copper inventory",
                "China PMI manufacturing",
                "Baltic dry index",
                "Goldman Sachs commodity"
            ]
            
            for keyword in market_keywords:
                try:
                    self.logger.info(f"ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¤œç´¢: {keyword}")
                    headlines = ek.get_news_headlines(query=keyword, count=3)
                    
                    if headlines is not None and len(headlines) > 0:
                        for _, row in headlines.iterrows():
                            story_id = row.get('storyId')
                            headline = row.get('text', 'N/A')
                            date = row.get('versionCreated', 'N/A')
                            source = row.get('sourceCode', 'N/A')
                            
                            # ãƒ‹ãƒ¥ãƒ¼ã‚¹æœ¬æ–‡å–å¾—ã‚’è©¦è¡Œ
                            news_body = "æœ¬æ–‡å–å¾—å¤±æ•—"
                            if story_id:
                                try:
                                    news_story = ek.get_news_story(story_id)
                                    if news_story and len(news_story) > 100:
                                        # æœ€åˆã®500æ–‡å­—ã‚’å–å¾—
                                        news_body = news_story[:500] + "..." if len(news_story) > 500 else news_story
                                    time.sleep(0.2)  # æœ¬æ–‡å–å¾—é–“éš”
                                except Exception as story_err:
                                    news_body = f"æœ¬æ–‡å–å¾—ã‚¨ãƒ©ãƒ¼: {str(story_err)}"
                            
                            news_data["market_moving_news"].append({
                                "keyword": keyword,
                                "headline": headline,
                                "body": news_body,
                                "date": str(date),
                                "source": source,
                                "story_id": story_id
                            })
                    
                    time.sleep(0.5)  # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é–“éš”
                    
                except Exception as e:
                    news_data["errors"].append(f"News search ({keyword}): {str(e)}")
            
            # ä¾›çµ¦é€”çµ¶ãƒ‹ãƒ¥ãƒ¼ã‚¹
            supply_keywords = ["copper mine strike", "Codelco production", "shipping delay metal"]
            
            for keyword in supply_keywords[:2]:  # åˆ¶é™ã—ã¦å®Ÿè¡Œ
                try:
                    headlines = ek.get_news_headlines(query=keyword, count=2)
                    
                    if headlines is not None and len(headlines) > 0:
                        for _, row in headlines.iterrows():
                            news_data["supply_disruption_news"].append({
                                "keyword": keyword,
                                "headline": row.get('text', 'N/A'),
                                "date": str(row.get('versionCreated', 'N/A')),
                                "source": row.get('sourceCode', 'N/A')
                            })
                    
                    time.sleep(0.5)
                    
                except Exception as e:
                    news_data["errors"].append(f"Supply news ({keyword}): {str(e)}")
            
            time.sleep(1)
            
        except Exception as e:
            self.logger.error(f"ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            news_data["errors"].append(f"General news error: {str(e)}")
        
        return news_data
    
    def get_enhanced_macro_data(self) -> Dict[str, Any]:
        """æ”¹è‰¯ç‰ˆãƒã‚¯ãƒ­çµŒæ¸ˆãƒ‡ãƒ¼ã‚¿å–å¾—"""
        self.logger.info("æ”¹è‰¯ç‰ˆãƒã‚¯ãƒ­çµŒæ¸ˆãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹...")
        
        macro_data = {
            "timestamp": datetime.now().isoformat(),
            "economic_indicators": {},
            "commodity_indices": {},
            "currency_rates": {},
            "errors": []
        }
        
        try:
            # ç¢ºå®Ÿã«å–å¾—ã§ãã‚‹ãƒã‚¯ãƒ­æŒ‡æ¨™RIC
            reliable_rics = {
                "us_dollar_index": ".DXY",
                "crude_oil_wti": "CLc1",
                "copper_lme_3m": "CMCU3",
                "aluminum_lme_3m": "CMAL3",
                "usd_jpy": "JPY=",
                "usd_cny": "CNY=",
                "us_10y_yield": "US10YT=RR"
            }
            
            for name, ric in reliable_rics.items():
                try:
                    data, err = ek.get_data(ric, ['CF_LAST', 'CF_DATE', 'CF_NAME', 'PCTCHNG'])
                    
                    if data is not None and not data.empty:
                        row = data.iloc[0]
                        value = row.get('CF_LAST')
                        change = row.get('PCTCHNG')
                        
                        if pd.notna(value):
                            macro_data["economic_indicators"][name] = {
                                "value": float(value),
                                "daily_change_pct": float(change) if pd.notna(change) else None,
                                "date": str(row.get('CF_DATE', 'N/A')),
                                "name": str(row.get('CF_NAME', name)),
                                "ric": ric
                            }
                            self.logger.info(f"âœ… {name}: {value}")
                        
                        # æ™‚ç³»åˆ—ãƒˆãƒ¬ãƒ³ãƒ‰ã‚‚å–å¾—
                        try:
                            end_date = datetime.now()
                            start_date = end_date - timedelta(days=7)
                            ts_data = ek.get_timeseries(
                                ric,
                                start_date=start_date.strftime('%Y-%m-%d'),
                                end_date=end_date.strftime('%Y-%m-%d'),
                                fields=['CLOSE']
                            )
                            if ts_data is not None and not ts_data.empty and len(ts_data) > 1:
                                week_change = ((ts_data['CLOSE'].iloc[-1] - ts_data['CLOSE'].iloc[0]) / ts_data['CLOSE'].iloc[0]) * 100
                                macro_data["economic_indicators"][name]["weekly_change_pct"] = round(week_change, 2)
                        except:
                            pass  # æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ããªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                    
                    time.sleep(0.3)
                    
                except Exception as e:
                    error_msg = f"{name} ({ric}): {str(e)}"
                    macro_data["errors"].append(error_msg)
                    self.logger.warning(f"âš ï¸  {error_msg}")
            
            # ãƒãƒ«ãƒãƒƒã‚¯æŒ‡æ•°ã®è©³ç´°å–å¾—
            try:
                baltic_data, err = ek.get_data(".BADI", ['CF_LAST', 'CF_DATE', 'CF_NAME', 'PCTCHNG'])
                if baltic_data is not None and not baltic_data.empty:
                    row = baltic_data.iloc[0]
                    value = row.get('CF_LAST')
                    if pd.notna(value):
                        macro_data["commodity_indices"]["baltic_dry_index"] = {
                            "value": float(value),
                            "daily_change_pct": float(row.get('PCTCHNG')) if pd.notna(row.get('PCTCHNG')) else None,
                            "date": str(row.get('CF_DATE', 'N/A')),
                            "significance": "ç‰©æµã‚³ã‚¹ãƒˆæŒ‡æ¨™ï¼šä¸Šæ˜‡ã¯ã‚³ãƒ³ã‚¿ãƒ³ã‚´è¦å› "
                        }
                        
                        # 30æ—¥ãƒˆãƒ¬ãƒ³ãƒ‰
                        try:
                            end_date = datetime.now()
                            start_date = end_date - timedelta(days=30)
                            baltic_ts = ek.get_timeseries(
                                ".BADI", 
                                start_date=start_date.strftime('%Y-%m-%d'),
                                end_date=end_date.strftime('%Y-%m-%d'),
                                fields=['CLOSE']
                            )
                            if baltic_ts is not None and not baltic_ts.empty:
                                month_change = ((float(value) - baltic_ts['CLOSE'].iloc[0]) / baltic_ts['CLOSE'].iloc[0]) * 100
                                macro_data["commodity_indices"]["baltic_dry_index"]["monthly_change_pct"] = round(month_change, 2)
                                self.logger.info(f"âœ… ãƒãƒ«ãƒãƒƒã‚¯æŒ‡æ•°: {value} (æœˆæ¬¡å¤‰å‹•: {month_change:.2f}%)")
                        except:
                            pass
            except Exception as e:
                macro_data["errors"].append(f"Baltic index: {str(e)}")
            
            time.sleep(1)
            
        except Exception as e:
            self.logger.error(f"ãƒã‚¯ãƒ­ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            macro_data["errors"].append(f"General macro error: {str(e)}")
        
        return macro_data
    
    def generate_enhanced_web_claude_report(self) -> str:
        """æ”¹è‰¯ç‰ˆWebç‰ˆClaudeç”¨ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        self.logger.info("æ”¹è‰¯ç‰ˆWebç‰ˆClaudeç”¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé–‹å§‹...")
        
        # å„ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®ãƒ‡ãƒ¼ã‚¿å–å¾—
        inventory_data = self.get_enhanced_lme_inventory()
        news_data = self.get_enhanced_news_data()
        macro_data = self.get_enhanced_macro_data()
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report_lines = []
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼
        report_lines.append("=" * 80)
        report_lines.append("ã€Webç‰ˆClaudeç”¨ã€‘æ”¹è‰¯ç‰ˆã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰äºˆæ¸¬ç²¾åº¦å‘ä¸Šãƒ‡ãƒ¼ã‚¿ãƒ¬ãƒãƒ¼ãƒˆ")
        report_lines.append("=" * 80)
        report_lines.append(f"ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}")
        report_lines.append(f"ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: Refinitiv EIKON APIï¼ˆæ”¹è‰¯ç‰ˆï¼‰")
        report_lines.append("")
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆéƒ¨åˆ†
        report_lines.append("ã€Claudeåˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€‘")
        report_lines.append("ä»¥ä¸‹ã®Refinitivã‹ã‚‰å–å¾—ã—ãŸãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é‡‘å±å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚’åŸºã«ã€")
        report_lines.append("LMEé‡‘å±å…ˆç‰©ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ï¼ˆã‚³ãƒ³ã‚¿ãƒ³ã‚´/ãƒãƒƒã‚¯ãƒ¯ãƒ¼ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰ã®äºˆæ¸¬åˆ†æã‚’è¡Œã£ã¦ãã ã•ã„ã€‚")
        report_lines.append("")
        report_lines.append("ã€é‡è¦ãªåˆ†æè¦ä»¶ã€‘")
        report_lines.append("- LMEåœ¨åº«ã®ã‚ªãƒ³ãƒ¯ãƒ©ãƒ³ãƒˆ vs ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒ¯ãƒ©ãƒ³ãƒˆã®æ§‹é€ åˆ†æ")
        report_lines.append("- ç‰©æµã‚³ã‚¹ãƒˆï¼ˆãƒãƒ«ãƒãƒƒã‚¯æŒ‡æ•°ï¼‰å¤‰å‹•ãŒCarry Costã«ä¸ãˆã‚‹å½±éŸ¿")
        report_lines.append("- æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ»ã‚¢ãƒŠãƒªã‚¹ãƒˆè¦‹è§£ã®ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æ")
        report_lines.append("- ãƒã‚¯ãƒ­çµŒæ¸ˆæŒ‡æ¨™ã¨ã‚³ãƒ¢ãƒ‡ã‚£ãƒ†ã‚£ä¾¡æ ¼ã®ç›¸é–¢åˆ†æ")
        report_lines.append("- çŸ­æœŸï¼ˆ1-2é€±é–“ï¼‰ãƒ»ä¸­æœŸï¼ˆ1-3ãƒ¶æœˆï¼‰ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰æ–¹å‘äºˆæ¸¬")
        report_lines.append("- å…·ä½“çš„ãªãƒˆãƒ¬ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æˆ¦ç•¥ã¨ãƒªã‚¹ã‚¯ã‚·ãƒŠãƒªã‚ª")
        report_lines.append("")
        
        # ã‚«ãƒ†ã‚´ãƒªãƒ¼1: è©³ç´°åœ¨åº«ãƒ‡ãƒ¼ã‚¿
        report_lines.append("=" * 60)
        report_lines.append("ã€ã‚«ãƒ†ã‚´ãƒªãƒ¼1ã€‘LMEåœ¨åº«è©³ç´°ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ¯ãƒ©ãƒ³ãƒˆåˆ†è§£ï¼‰")
        report_lines.append("=" * 60)
        
        if "lme_detailed_stocks" in inventory_data:
            for metal, stock_data in inventory_data["lme_detailed_stocks"].items():
                if stock_data:  # ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿è¡¨ç¤º
                    report_lines.append(f"\n--- {metal.upper()}åœ¨åº«æ§‹é€  ---")
                    
                    total_stock = stock_data.get("total", {}).get("value", "N/A")
                    on_warrant = stock_data.get("on_warrant", {}).get("value", "N/A")
                    cancelled = stock_data.get("cancelled", {}).get("value", "N/A")
                    
                    report_lines.append(f"  ç·åœ¨åº«é‡: {total_stock} ãƒˆãƒ³")
                    report_lines.append(f"  ã‚ªãƒ³ãƒ¯ãƒ©ãƒ³ãƒˆ: {on_warrant} ãƒˆãƒ³")
                    report_lines.append(f"  ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒ¯ãƒ©ãƒ³ãƒˆ: {cancelled} ãƒˆãƒ³")
                    
                    # æ¯”ç‡è¨ˆç®—
                    if isinstance(total_stock, (int, float)) and isinstance(cancelled, (int, float)) and total_stock > 0:
                        cancel_ratio = (cancelled / total_stock) * 100
                        report_lines.append(f"  ã‚­ãƒ£ãƒ³ã‚»ãƒ«ç‡: {cancel_ratio:.1f}% (ãƒãƒƒã‚¯ãƒ¯ãƒ¼ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³è¦å› )")
                    
                    date = stock_data.get("total", {}).get("date", "N/A")
                    report_lines.append(f"  æ›´æ–°æ—¥: {date}")
        
        # ãƒã‚§ãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®è£œå®Œ
        if "lme_warrant_status" in inventory_data and "chain_data" in inventory_data["lme_warrant_status"]:
            report_lines.append(f"\n--- LMEåœ¨åº«ã‚µãƒãƒªãƒ¼ï¼ˆãƒã‚§ãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿ï¼‰ ---")
            for item in inventory_data["lme_warrant_status"]["chain_data"]:
                name = item.get("name", "N/A")
                value = item.get("value", "N/A")
                date = item.get("date", "N/A")
                report_lines.append(f"  {name}: {value} ãƒˆãƒ³ (æ›´æ–°: {date})")
        
        # SHFEåœ¨åº«æ¯”è¼ƒ
        if "other_exchanges" in inventory_data and "SHFE" in inventory_data["other_exchanges"]:
            report_lines.append(f"\n--- SHFEåœ¨åº«ï¼ˆåœ°åŸŸæ¯”è¼ƒç”¨ï¼‰ ---")
            for metal, data in inventory_data["other_exchanges"]["SHFE"].items():
                value = data.get("value", "N/A")
                date = data.get("date", "N/A")
                report_lines.append(f"  {metal.capitalize()}: {value} ãƒˆãƒ³ (æ›´æ–°: {date})")
        
        # ã‚«ãƒ†ã‚´ãƒªãƒ¼2: å¸‚å ´ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãƒ‹ãƒ¥ãƒ¼ã‚¹
        report_lines.append("\n" + "=" * 60)
        report_lines.append("ã€ã‚«ãƒ†ã‚´ãƒªãƒ¼2ã€‘å¸‚å ´ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆæœ¬æ–‡ä»˜ãï¼‰")
        report_lines.append("=" * 60)
        
        if "market_moving_news" in news_data and news_data["market_moving_news"]:
            for i, news in enumerate(news_data["market_moving_news"][:6]):
                report_lines.append(f"\n--- ãƒ‹ãƒ¥ãƒ¼ã‚¹ {i+1} ({news.get('keyword', 'N/A')}) ---")
                report_lines.append(f"è¦‹å‡ºã—: {news.get('headline', 'N/A')}")
                report_lines.append(f"æœ¬æ–‡: {news.get('body', 'N/A')}")
                report_lines.append(f"æ—¥æ™‚: {news.get('date', 'N/A')} | ã‚½ãƒ¼ã‚¹: {news.get('source', 'N/A')}")
        
        if "supply_disruption_news" in news_data and news_data["supply_disruption_news"]:
            report_lines.append(f"\n--- ä¾›çµ¦é€”çµ¶é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ ---")
            for news in news_data["supply_disruption_news"]:
                report_lines.append(f"  â€¢ {news.get('headline', 'N/A')}")
                report_lines.append(f"    æ—¥æ™‚: {news.get('date', 'N/A')} | ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {news.get('keyword', 'N/A')}")
        
        # ã‚«ãƒ†ã‚´ãƒªãƒ¼3: ãƒã‚¯ãƒ­çµŒæ¸ˆãƒ»ã‚³ãƒ¢ãƒ‡ã‚£ãƒ†ã‚£æŒ‡æ¨™
        report_lines.append("\n" + "=" * 60)
        report_lines.append("ã€ã‚«ãƒ†ã‚´ãƒªãƒ¼3ã€‘ãƒã‚¯ãƒ­çµŒæ¸ˆãƒ»ã‚³ãƒ¢ãƒ‡ã‚£ãƒ†ã‚£æŒ‡æ¨™")
        report_lines.append("=" * 60)
        
        if "economic_indicators" in macro_data:
            report_lines.append(f"\n--- ä¸»è¦çµŒæ¸ˆæŒ‡æ¨™ ---")
            for name, data in macro_data["economic_indicators"].items():
                value = data.get("value", "N/A")
                daily_chg = data.get("daily_change_pct", "N/A")
                weekly_chg = data.get("weekly_change_pct", "N/A")
                date = data.get("date", "N/A")
                
                report_lines.append(f"  {data.get('name', name)}: {value}")
                if daily_chg != "N/A":
                    report_lines.append(f"    æ—¥æ¬¡å¤‰å‹•: {daily_chg:+.2f}%")
                if weekly_chg != "N/A":
                    report_lines.append(f"    é€±æ¬¡å¤‰å‹•: {weekly_chg:+.2f}%")
                report_lines.append(f"    æ›´æ–°: {date}")
                report_lines.append("")
        
        if "commodity_indices" in macro_data:
            report_lines.append(f"--- ç‰©æµãƒ»é‹è³ƒæŒ‡æ¨™ ---")
            for name, data in macro_data["commodity_indices"].items():
                value = data.get("value", "N/A")
                daily_chg = data.get("daily_change_pct", "N/A")
                monthly_chg = data.get("monthly_change_pct", "N/A")
                significance = data.get("significance", "")
                
                report_lines.append(f"  {name}: {value}")
                if daily_chg != "N/A":
                    report_lines.append(f"    æ—¥æ¬¡å¤‰å‹•: {daily_chg:+.2f}%")
                if monthly_chg != "N/A":
                    report_lines.append(f"    æœˆæ¬¡å¤‰å‹•: {monthly_chg:+.2f}%")
                if significance:
                    report_lines.append(f"    æ„ç¾©: {significance}")
                report_lines.append("")
        
        # ã‚¨ãƒ©ãƒ¼ã‚µãƒãƒªãƒ¼
        all_errors = []
        all_errors.extend(inventory_data.get("errors", []))
        all_errors.extend(news_data.get("errors", []))
        all_errors.extend(macro_data.get("errors", []))
        
        if all_errors:
            report_lines.append(f"\n--- ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼ãƒ»åˆ¶é™äº‹é … ---")
            for error in all_errors[:10]:  # æœ€åˆã®10å€‹ã®ã‚¨ãƒ©ãƒ¼ã‚’è¡¨ç¤º
                report_lines.append(f"  â€¢ {error}")
        
        # ãƒ•ãƒƒã‚¿ãƒ¼ãƒ»åˆ†ææŒ‡ç¤º
        report_lines.append("\n" + "=" * 80)
        report_lines.append("ã€è©³ç´°åˆ†ææŒ‡ç¤ºã€‘")
        report_lines.append("=" * 80)
        report_lines.append("")
        report_lines.append("ä»¥ä¸‹ã®è¦³ç‚¹ã‹ã‚‰ç·åˆçš„ãªã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰åˆ†æã‚’å®Ÿæ–½ã—ã¦ãã ã•ã„ï¼š")
        report_lines.append("")
        report_lines.append("1. åœ¨åº«æ§‹é€ åˆ†æ:")
        report_lines.append("   - ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒ¯ãƒ©ãƒ³ãƒˆæ¯”ç‡ã®é«˜ã„é‡‘å± â†’ ãƒãƒƒã‚¯ãƒ¯ãƒ¼ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³åœ§åŠ›")
        report_lines.append("   - LME vs SHFEåœ¨åº«æ¯”è¼ƒ â†’ åœ°åŸŸéœ€çµ¦æ ¼å·®")
        report_lines.append("   - ã‚ªãƒ³ãƒ¯ãƒ©ãƒ³ãƒˆæ¸›å°‘ãƒˆãƒ¬ãƒ³ãƒ‰ â†’ ç¾ç‰©ã‚¿ã‚¤ãƒˆåŒ–")
        report_lines.append("")
        report_lines.append("2. ç‰©æµã‚³ã‚¹ãƒˆè¦å› :")
        report_lines.append("   - ãƒãƒ«ãƒãƒƒã‚¯æŒ‡æ•°ä¸Šæ˜‡ â†’ è¼¸é€è²»å¢—åŠ  â†’ ã‚³ãƒ³ã‚¿ãƒ³ã‚´æ‹¡å¤§è¦å› ")
        report_lines.append("   - é€±æ¬¡ãƒ»æœˆæ¬¡ãƒˆãƒ¬ãƒ³ãƒ‰ç¶™ç¶šæ€§è©•ä¾¡")
        report_lines.append("")
        report_lines.append("3. ãƒãƒ¼ã‚±ãƒƒãƒˆã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ:")
        report_lines.append("   - ãƒ‹ãƒ¥ãƒ¼ã‚¹æœ¬æ–‡ã‹ã‚‰èª­ã¿å–ã‚Œã‚‹å¸‚å ´å¿ƒç†")
        report_lines.append("   - ã‚¢ãƒŠãƒªã‚¹ãƒˆè¦‹è§£ã®æ–¹å‘æ€§ï¼ˆå¼·æ°—/å¼±æ°—ï¼‰")
        report_lines.append("   - ä¾›çµ¦é€”çµ¶ãƒªã‚¹ã‚¯ã®å®šé‡çš„å½±éŸ¿")
        report_lines.append("")
        report_lines.append("4. ãƒã‚¯ãƒ­ç’°å¢ƒ:")
        report_lines.append("   - ãƒ‰ãƒ«æŒ‡æ•°ãƒ»é‡‘åˆ©å¤‰å‹•ãŒCarry Costã«ä¸ãˆã‚‹å½±éŸ¿")
        report_lines.append("   - åŸæ²¹ä¾¡æ ¼ã¨ãƒ¡ã‚¿ãƒ«ç›¸é–¢æ€§")
        report_lines.append("   - ç‚ºæ›¿å¤‰å‹•ã®åœ°åŸŸéœ€çµ¦ã¸ã®å½±éŸ¿")
        report_lines.append("")
        report_lines.append("5. å®Ÿè·µçš„ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰æˆ¦ç•¥:")
        report_lines.append("   - é‡‘å±åˆ¥ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰æ–¹å‘äºˆæ¸¬ï¼ˆã‚³ãƒ³ã‚¿ãƒ³ã‚´/ãƒãƒƒã‚¯ãƒ¯ãƒ¼ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰")
        report_lines.append("   - æœŸé–“æ§‹é€ å¤‰åŒ–ã®å…·ä½“çš„æ™‚æœŸäºˆæƒ³")
        report_lines.append("   - ãƒªã‚¹ã‚¯ç®¡ç†ã‚’å«ã‚€å…·ä½“çš„ãƒã‚¸ã‚·ãƒ§ãƒ³æˆ¦ç•¥")
        report_lines.append("   - ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹ãƒ»åˆ©ç¢ºãƒ¬ãƒ™ãƒ«ã®ææ¡ˆ")
        report_lines.append("")
        report_lines.append("=" * 80)
        
        return "\n".join(report_lines)
    
    def save_report(self, report_content: str, filename: str = None) -> str:
        """ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        if filename is None:
            filename = f"Enhanced_Refinitiv_Spread_Analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(report_content)
            self.logger.info(f"æ”¹è‰¯ç‰ˆãƒ¬ãƒãƒ¼ãƒˆä¿å­˜å®Œäº†: {filename}")
            return filename
        except Exception as e:
            self.logger.error(f"ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            raise

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    try:
        reporter = EnhancedRefinitivWebClaudeReporter()
        
        print("ğŸš€ æ”¹è‰¯ç‰ˆWebç‰ˆClaudeç”¨ Refinitivãƒ‡ãƒ¼ã‚¿ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ")
        print("=" * 60)
        print("â€¢ LMEåœ¨åº«: ã‚ªãƒ³ãƒ¯ãƒ©ãƒ³ãƒˆãƒ»ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒ¯ãƒ©ãƒ³ãƒˆåˆ†è§£")
        print("â€¢ ãƒ‹ãƒ¥ãƒ¼ã‚¹: æœ¬æ–‡å–å¾—æ©Ÿèƒ½ä»˜ã")  
        print("â€¢ ãƒã‚¯ãƒ­æŒ‡æ¨™: ç¢ºå®ŸãªRICã§ã®é€±æ¬¡ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ")
        print("=" * 60)
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report_content = reporter.generate_enhanced_web_claude_report()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        saved_filename = reporter.save_report(report_content)
        
        print(f"\nâœ… æ”¹è‰¯ç‰ˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†!")
        print(f"ğŸ“„ ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«: {saved_filename}")
        print(f"ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {len(report_content.encode('utf-8')):,} bytes")
        print("\nğŸ”— ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Webç‰ˆClaudeã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦è©³ç´°åˆ†æã‚’ä¾é ¼ã—ã¦ãã ã•ã„ã€‚")
        print("ğŸ’¡ æ”¹è‰¯ç‚¹: ãƒ¯ãƒ©ãƒ³ãƒˆåˆ†è§£ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹æœ¬æ–‡ã€ç¢ºå®Ÿãªãƒã‚¯ãƒ­æŒ‡æ¨™")
        
        return 0
        
    except Exception as e:
        print(f"âŒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        return 1

if __name__ == "__main__":
    exit(main())